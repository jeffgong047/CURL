{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pAMtGe4ZW1W"
      },
      "source": [
        "# Deep Learning Methods for COVID-QA Medical Retrieval\n",
        "\n",
        "## DPR and SPLADE for Medical Domain Question Answering\n",
        "\n",
        "This notebook implements advanced deep learning retrieval methods for medical domain question answering using the COVID-QA dataset:\n",
        "\n",
        "1. **Load COVID-QA Dataset** - Medical literature Q&A pairs\n",
        "2. **Implement DPR** - Dense Passage Retrieval with dual encoders\n",
        "3. **Implement SPLADE** - Sparse Lexical And Expansion model\n",
        "4. **Define Evaluation Framework** - Retrieval metrics for medical domain\n",
        "5. **Run and Compare Methods** - Performance analysis\n",
        "\n",
        "### **Why DPR and SPLADE for Medical Domain?**\n",
        "\n",
        "- **DPR**: Dense neural retrieval captures semantic similarity between medical questions and literature, handling synonyms and paraphrases common in medical terminology\n",
        "- **SPLADE**: Neural sparse retrieval maintains interpretability while expanding medical terms, crucial for expert validation in medical applications\n",
        "\n",
        "### **Focus**: Retrieval effectiveness for medical domain questions, not extractive QA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGWlSjrAsNhk",
        "outputId": "f1806412-312e-4303-8d54-b90c45d04b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.33.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#use wandb for managing experiments\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('data'):\n",
        "  os.mkdir('data')"
      ],
      "metadata": {
        "id": "n2vcHJjSs87x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYefUrjoZW1b",
        "outputId": "9970370c-7c57-4f8c-e0cb-bed3bd03bbfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Transformers and Sentence Transformers loaded successfully!\n",
            "   üî• PyTorch version: 2.6.0+cu124\n",
            "   ü§ó Using device: CPU\n",
            "üìÅ Loading COVID-QA dataset with proper train/validation/test splits...\n",
            "‚úÖ Successfully loaded COVID-QA dataset!\n",
            "   ‚Ä¢ Community: 642 QA pairs\n",
            "   ‚Ä¢ News: 481 QA pairs\n",
            "   ‚Ä¢ Multilingual: 888 QA pairs\n",
            "   ‚Ä¢ Total combined: 2,008 QA pairs\n",
            "\n",
            "üîÑ Creating train/validation/test splits...\n",
            "   ‚Ä¢ Training set: 1,606 QA pairs (80%)\n",
            "   ‚Ä¢ Validation set: 201 QA pairs (10%)\n",
            "   ‚Ä¢ Test set: 201 QA pairs (10%)\n",
            "\n",
            "üìä Dataset source distribution:\n",
            "   Train:\n",
            "      ‚Ä¢ multilingual: 709 (44.1%)\n",
            "      ‚Ä¢ community: 514 (32.0%)\n",
            "      ‚Ä¢ news: 383 (23.8%)\n",
            "   Validation:\n",
            "      ‚Ä¢ multilingual: 89 (44.3%)\n",
            "      ‚Ä¢ community: 64 (31.8%)\n",
            "      ‚Ä¢ news: 48 (23.9%)\n",
            "   Test:\n",
            "      ‚Ä¢ multilingual: 89 (44.3%)\n",
            "      ‚Ä¢ community: 64 (31.8%)\n",
            "      ‚Ä¢ news: 48 (23.9%)\n",
            "\n",
            "üìà Dataset Statistics:\n",
            "   Training set:\n",
            "      ‚Ä¢ Average question length: 325.9 chars\n",
            "      ‚Ä¢ Average answer length: 1057.0 chars\n",
            "   Test set:\n",
            "      ‚Ä¢ Average question length: 358.4 chars\n",
            "      ‚Ä¢ Average answer length: 970.9 chars\n",
            "\n",
            "üìù Sample QA pairs:\n",
            "   Training sample:\n",
            "      Q: I am currently in a job in the US (on STEM OPT). I had a postdoc offer from a large US university th...\n",
            "      A: A signed offer letter is normally a valid contract.  Usually it is the only contract document.  Only...\n",
            "   Test sample:\n",
            "      Q: ¬øExisten medicamentos o terapias que permitan prevenir o curar la COVID-19?...\n",
            "      A: Aunque algunos remedios occidentales, tradicionales o caseros pueden proporcionar confort y aliviar ...\n",
            "\n",
            "üéØ Corpus for negative sampling: 1,606 passages\n",
            "\n",
            "üéØ Dataset Loading Complete!\n",
            "üìä Ready for proper train/validation/test evaluation of deep learning methods!\n",
            "   ‚Ä¢ Training data: 1,606 QA pairs\n",
            "   ‚Ä¢ Validation data: 201 QA pairs\n",
            "   ‚Ä¢ Test data: 201 QA pairs\n",
            "   ‚Ä¢ No data leakage: Test set completely separate from training\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import Libraries and Load COVID-QA Dataset with Proper Splits\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Core deep learning libraries\n",
        "try:\n",
        "    from transformers import (\n",
        "        AutoTokenizer, AutoModel,\n",
        "        BertTokenizer, BertModel,\n",
        "        TrainingArguments, Trainer\n",
        "    )\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    print(\"‚úÖ Transformers and Sentence Transformers loaded successfully!\")\n",
        "    print(f\"   üî• PyTorch version: {torch.__version__}\")\n",
        "    print(f\"   ü§ó Using device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "    DL_LIBRARIES_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Deep learning libraries not available. Please install:\")\n",
        "    print(\"   pip install torch transformers sentence-transformers\")\n",
        "    DL_LIBRARIES_AVAILABLE = False\n",
        "\n",
        "# Traditional libraries for comparison\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import re\n",
        "import json\n",
        "\n",
        "# Load COVID-QA Dataset with Proper Splits\n",
        "print(\"üìÅ Loading COVID-QA dataset with proper train/validation/test splits...\")\n",
        "\n",
        "try:\n",
        "    # Load dataset files\n",
        "    community_df = pd.read_csv('data/community.csv')\n",
        "    news_df = pd.read_csv('data/news.csv')\n",
        "    multilingual_df = pd.read_csv('data/multilingual.csv')\n",
        "\n",
        "    # Clean and process each dataset\n",
        "    def clean_dataframe(df, source_name):\n",
        "        df_clean = df.copy()\n",
        "        df_clean['dataset_source'] = source_name\n",
        "        df_clean['question'] = df_clean['question'].fillna('').astype(str)\n",
        "        df_clean['answer'] = df_clean['answer'].fillna('').astype(str)\n",
        "        return df_clean[['question', 'answer', 'dataset_source']]\n",
        "\n",
        "    # Process all datasets\n",
        "    community_clean = clean_dataframe(community_df, 'community')\n",
        "    news_clean = clean_dataframe(news_df, 'news')\n",
        "    multilingual_clean = clean_dataframe(multilingual_df, 'multilingual')\n",
        "\n",
        "    # Combine datasets\n",
        "    df_combined = pd.concat([community_clean, news_clean, multilingual_clean], ignore_index=True)\n",
        "\n",
        "    # Remove empty entries\n",
        "    df_combined = df_combined[(df_combined['question'].str.len() > 0) & (df_combined['answer'].str.len() > 0)]\n",
        "\n",
        "    print(f\"‚úÖ Successfully loaded COVID-QA dataset!\")\n",
        "    print(f\"   ‚Ä¢ Community: {len(community_clean):,} QA pairs\")\n",
        "    print(f\"   ‚Ä¢ News: {len(news_clean):,} QA pairs\")\n",
        "    print(f\"   ‚Ä¢ Multilingual: {len(multilingual_clean):,} QA pairs\")\n",
        "    print(f\"   ‚Ä¢ Total combined: {len(df_combined):,} QA pairs\")\n",
        "\n",
        "    # Create proper train/validation/test splits\n",
        "    print(f\"\\nüîÑ Creating train/validation/test splits...\")\n",
        "\n",
        "    # First split: 80% train, 20% temp\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_combined,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=df_combined['dataset_source']\n",
        "    )\n",
        "\n",
        "    # Second split: 10% validation, 10% test (from the 20% temp)\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=0.5,\n",
        "        random_state=42,\n",
        "        stratify=temp_df['dataset_source']\n",
        "    )\n",
        "\n",
        "    print(f\"   ‚Ä¢ Training set: {len(train_df):,} QA pairs (80%)\")\n",
        "    print(f\"   ‚Ä¢ Validation set: {len(val_df):,} QA pairs (10%)\")\n",
        "    print(f\"   ‚Ä¢ Test set: {len(test_df):,} QA pairs (10%)\")\n",
        "\n",
        "    # Show dataset source distribution\n",
        "    print(f\"\\nüìä Dataset source distribution:\")\n",
        "    for split_name, split_df in [(\"Train\", train_df), (\"Validation\", val_df), (\"Test\", test_df)]:\n",
        "        source_counts = split_df['dataset_source'].value_counts()\n",
        "        print(f\"   {split_name}:\")\n",
        "        for source, count in source_counts.items():\n",
        "            print(f\"      ‚Ä¢ {source}: {count:,} ({count/len(split_df)*100:.1f}%)\")\n",
        "\n",
        "    # Extract data for each split\n",
        "    train_questions = train_df['question'].tolist()\n",
        "    train_answers = train_df['answer'].tolist()\n",
        "\n",
        "    val_questions = val_df['question'].tolist()\n",
        "    val_answers = val_df['answer'].tolist()\n",
        "\n",
        "    test_questions = test_df['question'].tolist()\n",
        "    test_answers = test_df['answer'].tolist()\n",
        "\n",
        "    # Dataset statistics\n",
        "    print(f\"\\nüìà Dataset Statistics:\")\n",
        "    print(f\"   Training set:\")\n",
        "    print(f\"      ‚Ä¢ Average question length: {train_df['question'].str.len().mean():.1f} chars\")\n",
        "    print(f\"      ‚Ä¢ Average answer length: {train_df['answer'].str.len().mean():.1f} chars\")\n",
        "    print(f\"   Test set:\")\n",
        "    print(f\"      ‚Ä¢ Average question length: {test_df['question'].str.len().mean():.1f} chars\")\n",
        "    print(f\"      ‚Ä¢ Average answer length: {test_df['answer'].str.len().mean():.1f} chars\")\n",
        "\n",
        "    # Show sample from each split\n",
        "    print(f\"\\nüìù Sample QA pairs:\")\n",
        "    print(f\"   Training sample:\")\n",
        "    sample_train = train_df.iloc[0]\n",
        "    print(f\"      Q: {sample_train['question'][:100]}...\")\n",
        "    print(f\"      A: {sample_train['answer'][:100]}...\")\n",
        "\n",
        "    print(f\"   Test sample:\")\n",
        "    sample_test = test_df.iloc[0]\n",
        "    print(f\"      Q: {sample_test['question'][:100]}...\")\n",
        "    print(f\"      A: {sample_test['answer'][:100]}...\")\n",
        "\n",
        "    # Create corpus for negative sampling (using training answers only)\n",
        "    corpus_for_negatives = train_answers.copy()\n",
        "    print(f\"\\nüéØ Corpus for negative sampling: {len(corpus_for_negatives):,} passages\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå COVID-QA data files not found!\")\n",
        "    print(\"Please ensure these files exist in the 'data/' directory:\")\n",
        "    print(\"   ‚Ä¢ community.csv\")\n",
        "    print(\"   ‚Ä¢ news.csv\")\n",
        "    print(\"   ‚Ä¢ multilingual.csv\")\n",
        "    raise FileNotFoundError\n",
        "\n",
        "\n",
        "print(f\"\\nüéØ Dataset Loading Complete!\")\n",
        "print(f\"üìä Ready for proper train/validation/test evaluation of deep learning methods!\")\n",
        "print(f\"   ‚Ä¢ Training data: {len(train_questions):,} QA pairs\")\n",
        "print(f\"   ‚Ä¢ Validation data: {len(val_questions):,} QA pairs\")\n",
        "print(f\"   ‚Ä¢ Test data: {len(test_questions):,} QA pairs\")\n",
        "print(f\"   ‚Ä¢ No data leakage: Test set completely separate from training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "61eecc772a5b45d6a539c748fbb4e1fd",
            "c9e0ad48f29b4ac08eaf0f516cbc971c",
            "9eaeaad999704d23b97ccac35f589504",
            "11f31222b0bd469b86aa50bd53b9654c",
            "2716ed75ea4e445cbbbb8a454a573547",
            "5cf90e704a2b46c2a2d4f8a1ff5ef9c8",
            "34707047cf5f4b9ab5dcc854cfbc2422",
            "69997ad0a73b4ada8d285185f4257e27",
            "600af2cd58f04576a7b37a5faf087fb3",
            "d8d4fcc392c7475d9985e1bfa3c5c403",
            "7a4c639eab6f48e9bf2149e8587a7cc6",
            "3f813d72755940bb91a0a1bb3ef651a7",
            "aa5e1d55e774413ca688f0a5e0d7c788",
            "e43fdf6398da4bfdbb35a36b6ee559db",
            "589b58c742dd4c13842480d313d09a3b",
            "1ffeec198fce43efb4a8af6f66155a50",
            "e95fc1d10d1c45c8a841ed9203192a64",
            "5351742d64ae4235a607986c0bae2ea2",
            "72ad0773b3054f54b229384f120f7d3a",
            "e959223194b942cc8af2c4a59fa818a9",
            "830d236cee014cac906f2a951fb9255d",
            "4de2b7454f76465cb62cc4e6561d0a4c",
            "bb10244ca9124435a229068b16a4d4f5",
            "2a02f9a8e58949e3be976c2fc4b750ea",
            "9e24c88ad5494b1a900fdd0bb4fd8565",
            "56581235eecb45199ef20e47e7474465",
            "8e55c059441446bfa99ed8b1b2acd58d",
            "b936933003e94549b0bc212e6b92a87b",
            "37b8fdd7307843c0a39107b9690f9380",
            "19eac41c001649258981f2702123b5c9",
            "32608f26e2424ed29f26268f4e4dd90c",
            "5c5adb0412db4d2b85c607b7d93bcf04",
            "c22a908a6604479b8341ad0d095aae5d",
            "316ac419230240a686fc262be21ff5fe",
            "ef8d03837af3474aac6f86677de2982a",
            "5906493105b4415c9917964354c5b74f",
            "b39a3ce4080045f2ae5c290e76aba12d",
            "cfecf6e6468f47bfbb732e975f9dbb6a",
            "7129af829b57492480901ab77bcb95be",
            "c165b859b0964bf19663076e92e1e6af",
            "cf0b395bcf4341a6bcd2d1901d82f491",
            "5c66e375115e46b1a755f1ea60800df3",
            "bcef01737be94b9ab68be9898f1fd491",
            "e18cc7a784f64a0a91be42abaf6988ca",
            "10a092aec6994a9580dddc7eef53c418",
            "19da33e3d83a4922bd894fdcb98c053b",
            "a7927f3606a246278c9a52d916f3cdfa",
            "529bf1d8e99046e9aa4adb9671802e81",
            "f3ea517c03d546e0b5dfdaa64b8ece4b",
            "ef4731826f844a5386962ec2f48e9436",
            "7f5f881fe4cb46c69c81f1fd00716be9",
            "2f3a36b24ef0455eb9d920f70c7caf6d",
            "7254203a300f44a5949554414480414c",
            "2e577115d63f4a9a92dd69f9b6d3a555",
            "9d59233efb0f488d85bf2e986a569dea"
          ]
        },
        "id": "Sn24TvbHZW1e",
        "outputId": "f47b16a6-c86f-4917-ce51-48036f8d1329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Initializing Dense Passage Retrieval (DPR) with In-Batch Negatives...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61eecc772a5b45d6a539c748fbb4e1fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f813d72755940bb91a0a1bb3ef651a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb10244ca9124435a229068b16a4d4f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "316ac419230240a686fc262be21ff5fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10a092aec6994a9580dddc7eef53c418"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ DPR trainer initialized successfully!\n",
            "   üî• Device: cpu\n",
            "   üìê Projection dim: 768\n",
            "   üîÄ Dual encoders: Question + Passage\n",
            "   üéØ Negative sampling strategy: In-batch negatives only\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Implement Dense Passage Retrieval (DPR) with Training\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "# Remove unused imports for BM25\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import os # Import os for checkpointing\n",
        "\n",
        "class DPREncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    DPR Encoder (can be used for both questions and passages)\n",
        "    Based on BERT with projection head\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name='bert-base-uncased', projection_dim=768):\n",
        "        super(DPREncoder, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.projection = nn.Linear(self.bert.config.hidden_size, projection_dim)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # Use [CLS] token representation\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
        "        projected = self.projection(self.dropout(pooled_output))\n",
        "        return projected\n",
        "\n",
        "class DPRTrainer:\n",
        "    \"\"\"\n",
        "    Dense Passage Retrieval trainer with sophisticated negative sampling\n",
        "    Implements the full training strategy from Karpukhin et al. 2020\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name='bert-base-uncased', projection_dim=768, learning_rate=2e-5):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Dual encoders for questions and passages\n",
        "        self.question_encoder = DPREncoder(model_name, projection_dim).to(self.device)\n",
        "        self.passage_encoder = DPREncoder(model_name, projection_dim).to(self.device)\n",
        "\n",
        "        # Tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        # Optimizer\n",
        "        self.optimizer = optim.AdamW(\n",
        "            list(self.question_encoder.parameters()) + list(self.passage_encoder.parameters()),\n",
        "            lr=learning_rate\n",
        "        )\n",
        "\n",
        "        self.projection_dim = projection_dim\n",
        "\n",
        "    def encode_batch(self, texts, encoder, max_length=512):\n",
        "        \"\"\"\n",
        "        Encode a batch of texts using the specified encoder\n",
        "        \"\"\"\n",
        "        # Tokenize\n",
        "        encoded = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoded['input_ids'].to(self.device)\n",
        "        attention_mask = encoded['attention_mask'].to(self.device)\n",
        "\n",
        "        # Encode\n",
        "        # Ensure gradients are tracked during training\n",
        "        if encoder.training:\n",
        "             embeddings = encoder(input_ids, attention_mask)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                embeddings = encoder(input_ids, attention_mask)\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "    def compute_similarity_matrix(self, question_embeddings, passage_embeddings):\n",
        "        \"\"\"\n",
        "        Compute similarity matrix between questions and passages\n",
        "        Returns: (batch_size, num_passages) similarity matrix\n",
        "        \"\"\"\n",
        "        # Normalize embeddings\n",
        "        question_embeddings = F.normalize(question_embeddings, p=2, dim=1)\n",
        "        passage_embeddings = F.normalize(passage_embeddings, p=2, dim=1)\n",
        "\n",
        "        # Compute similarity matrix S = Q * P^T\n",
        "        similarity_matrix = torch.matmul(question_embeddings, passage_embeddings.transpose(0, 1))\n",
        "\n",
        "        return similarity_matrix\n",
        "\n",
        "    def train_step(self, questions, passages):\n",
        "        \"\"\"\n",
        "        Training step with in-batch negatives only\n",
        "        \"\"\"\n",
        "        batch_size = len(questions)\n",
        "\n",
        "        # Encode questions and passages\n",
        "        question_embeddings = self.encode_batch(questions, self.question_encoder)\n",
        "        passage_embeddings = self.encode_batch(passages, self.passage_encoder)\n",
        "\n",
        "        # Compute similarity matrix (B x B)\n",
        "        # In-batch negatives mean the positive pairs are on the diagonal\n",
        "        similarity_matrix = self.compute_similarity_matrix(question_embeddings, passage_embeddings)\n",
        "\n",
        "        # Labels: positive pairs are on diagonal (i=j)\n",
        "        labels = torch.arange(batch_size).to(self.device)\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        temperature = 0.1\n",
        "        similarity_matrix = similarity_matrix / temperature\n",
        "\n",
        "        # Cross-entropy loss\n",
        "        # This loss maximizes similarity of (qi, pi) pairs and minimizes (qi, pj) for i != j\n",
        "        loss = F.cross_entropy(similarity_matrix, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            list(self.question_encoder.parameters()) + list(self.passage_encoder.parameters()),\n",
        "            max_norm=1.0\n",
        "        )\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def train_epoch(self, train_data, batch_size, epoch, val_questions, val_answers):\n",
        "        \"\"\"\n",
        "        Train for one epoch with comprehensive validation, and save checkpoint with metrics\n",
        "\n",
        "        Args:\n",
        "            train_data: List of (question, passage) pairs\n",
        "            batch_size: Training batch size\n",
        "            epoch: Current epoch number (for logging and checkpointing)\n",
        "            val_questions: List of validation questions\n",
        "            val_answers: List of validation answers\n",
        "\n",
        "        Returns:\n",
        "            Average training loss and comprehensive validation metrics for the epoch\n",
        "        \"\"\"\n",
        "        self.question_encoder.train()\n",
        "        self.passage_encoder.train()\n",
        "\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        # Shuffle training data\n",
        "        random.shuffle(train_data)\n",
        "\n",
        "        for i in tqdm(range(0, len(train_data), batch_size), desc=\"Training DPR\"):\n",
        "            batch_data = train_data[i:i+batch_size]\n",
        "\n",
        "            # Extract questions and passages\n",
        "            questions = [item[0] for item in batch_data]\n",
        "            passages = [item[1] for item in batch_data]\n",
        "\n",
        "            # Only train if batch size > 1 to have in-batch negatives\n",
        "            if len(questions) > 1:\n",
        "                 loss = self.train_step(questions, passages)\n",
        "                 total_loss += loss\n",
        "                 num_batches += 1\n",
        "                 # Log batch loss to wandb\n",
        "                 if wandb.run:\n",
        "                     wandb.log({\"dpr/batch_loss\": loss}, step=epoch * (len(train_data) // batch_size) + num_batches)\n",
        "\n",
        "            else:\n",
        "                print(f\"Skipping batch {i//batch_size} with size {len(questions)} as in-batch negatives require batch size > 1.\")\n",
        "\n",
        "        avg_train_loss = total_loss / num_batches if num_batches > 0 else 0\n",
        "\n",
        "        # Comprehensive Validation\n",
        "        print(f\"   ‚Ä¢ Performing comprehensive validation...\")\n",
        "        val_subset_size = min(50, len(val_questions))  # Increased validation subset size for better metrics\n",
        "        val_passage_embeddings = self.encode_for_retrieval(val_answers[:val_subset_size], 'passage')\n",
        "\n",
        "        # Initialize metrics tracking\n",
        "        top_k_accuracies = {1: 0, 5: 0, 10: 0, 20: 0}\n",
        "        val_predictions = []\n",
        "\n",
        "        # Evaluate validation set\n",
        "        for i, question in enumerate(val_questions[:val_subset_size]):\n",
        "            results_list = self.retrieve(question, val_passage_embeddings, val_answers[:val_subset_size], top_k=20)\n",
        "\n",
        "            if results_list:\n",
        "                # Get top-1 prediction for QA metrics\n",
        "                best_answer = results_list[0][2]\n",
        "                val_predictions.append(best_answer)\n",
        "\n",
        "                # Calculate top-k accuracies\n",
        "                correct_answer = val_answers[i]\n",
        "                retrieved_answers = [r[2] for r in results_list]\n",
        "\n",
        "                for k in [1, 5, 10, 20]:\n",
        "                    if correct_answer in retrieved_answers[:k]:\n",
        "                        top_k_accuracies[k] += 1\n",
        "            else:\n",
        "                val_predictions.append(\"\")\n",
        "\n",
        "        # Calculate final metrics\n",
        "        for k in top_k_accuracies:\n",
        "            top_k_accuracies[k] = top_k_accuracies[k] / val_subset_size if val_subset_size > 0 else 0.0\n",
        "\n",
        "        # QA performance metrics (F1 and Exact Match)\n",
        "        from collections import Counter\n",
        "        import re\n",
        "\n",
        "        def normalize_answer(text):\n",
        "            text = text.lower()\n",
        "            text = re.sub(r'[^\\w\\s]', '', text)\n",
        "            text = ' '.join(text.split())\n",
        "            return text\n",
        "\n",
        "        def exact_match(prediction, ground_truth):\n",
        "            return float(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "        def f1_score(prediction, ground_truth):\n",
        "            pred_tokens = normalize_answer(prediction).split()\n",
        "            gt_tokens = normalize_answer(ground_truth).split()\n",
        "\n",
        "            if len(pred_tokens) == 0 and len(gt_tokens) == 0:\n",
        "                return 1.0\n",
        "            if len(pred_tokens) == 0 or len(gt_tokens) == 0:\n",
        "                return 0.0\n",
        "\n",
        "            common_tokens = Counter(pred_tokens) & Counter(gt_tokens)\n",
        "            num_same = sum(common_tokens.values())\n",
        "\n",
        "            if num_same == 0:\n",
        "                return 0.0\n",
        "\n",
        "            precision = num_same / len(pred_tokens)\n",
        "            recall = num_same / len(gt_tokens)\n",
        "\n",
        "            return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "        # Calculate QA metrics\n",
        "        exact_matches = [exact_match(pred, gt) for pred, gt in zip(val_predictions, val_answers[:val_subset_size])]\n",
        "        f1_scores = [f1_score(pred, gt) for pred, gt in zip(val_predictions, val_answers[:val_subset_size])]\n",
        "\n",
        "        val_exact_match = np.mean(exact_matches) if exact_matches else 0.0\n",
        "        val_f1 = np.mean(f1_scores) if f1_scores else 0.0\n",
        "\n",
        "        print(f\"   ‚Ä¢ Validation Results (subset size: {val_subset_size}):\")\n",
        "        print(f\"     - Top-1 accuracy: {top_k_accuracies[1]:.3f}\")\n",
        "        print(f\"     - Top-5 accuracy: {top_k_accuracies[5]:.3f}\")\n",
        "        print(f\"     - Top-10 accuracy: {top_k_accuracies[10]:.3f}\")\n",
        "        print(f\"     - Top-20 accuracy: {top_k_accuracies[20]:.3f}\")\n",
        "        print(f\"     - Exact Match: {val_exact_match:.3f}\")\n",
        "        print(f\"     - F1 Score: {val_f1:.3f}\")\n",
        "\n",
        "        # Log comprehensive epoch metrics to wandb\n",
        "        if wandb.run:\n",
        "            wandb.log({\n",
        "                \"dpr/epoch_loss\": avg_train_loss,\n",
        "                \"dpr/val_top_1_accuracy\": top_k_accuracies[1],\n",
        "                \"dpr/val_top_5_accuracy\": top_k_accuracies[5],\n",
        "                \"dpr/val_top_10_accuracy\": top_k_accuracies[10],\n",
        "                \"dpr/val_top_20_accuracy\": top_k_accuracies[20],\n",
        "                \"dpr/val_exact_match\": val_exact_match,\n",
        "                \"dpr/val_f1\": val_f1\n",
        "            }, step=epoch)\n",
        "\n",
        "        # Save checkpoint after each epoch with comprehensive metrics\n",
        "        checkpoint_dir = \"dpr_checkpoints\"\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f\"dpr_epoch_{epoch+1}.pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'question_encoder_state_dict': self.question_encoder.state_dict(),\n",
        "            'passage_encoder_state_dict': self.passage_encoder.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'loss': avg_train_loss,\n",
        "            'val_top_1_accuracy': top_k_accuracies[1],\n",
        "            'val_top_5_accuracy': top_k_accuracies[5],\n",
        "            'val_top_10_accuracy': top_k_accuracies[10],\n",
        "            'val_top_20_accuracy': top_k_accuracies[20],\n",
        "            'val_exact_match': val_exact_match,\n",
        "            'val_f1': val_f1,\n",
        "            'val_subset_size': val_subset_size\n",
        "        }, checkpoint_path)\n",
        "        print(f\"Checkpoint saved to {checkpoint_path}\")\n",
        "\n",
        "        # Log checkpoint artifact to wandb\n",
        "        if wandb.run:\n",
        "            artifact = wandb.Artifact(f'dpr-model-epoch-{epoch+1}', type='model')\n",
        "            artifact.add_file(checkpoint_path)\n",
        "            wandb.log_artifact(artifact)\n",
        "\n",
        "        # Return comprehensive validation metrics\n",
        "        epoch_metrics = {\n",
        "            'loss': avg_train_loss,\n",
        "            'top_1_accuracy': top_k_accuracies[1],\n",
        "            'top_5_accuracy': top_k_accuracies[5],\n",
        "            'top_10_accuracy': top_k_accuracies[10],\n",
        "            'top_20_accuracy': top_k_accuracies[20],\n",
        "            'exact_match': val_exact_match,\n",
        "            'f1': val_f1,\n",
        "            'val_subset_size': val_subset_size\n",
        "        }\n",
        "\n",
        "        return avg_train_loss, epoch_metrics\n",
        "\n",
        "    def encode_for_retrieval(self, texts, encoder_type='passage', batch_size=32):\n",
        "        \"\"\"\n",
        "        Encode texts for retrieval (inference mode)\n",
        "        \"\"\"\n",
        "        encoder = self.question_encoder if encoder_type == 'question' else self.passage_encoder\n",
        "        encoder.eval()\n",
        "\n",
        "        all_embeddings = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, len(texts), batch_size):\n",
        "                batch_texts = texts[i:i+batch_size]\n",
        "                embeddings = self.encode_batch(batch_texts, encoder)\n",
        "                all_embeddings.append(embeddings)\n",
        "\n",
        "        return torch.cat(all_embeddings, dim=0)\n",
        "\n",
        "    def retrieve(self, query, passage_embeddings, passages, top_k=5):\n",
        "        \"\"\"\n",
        "        Retrieve top-k passages for a query\n",
        "        \"\"\"\n",
        "        # Encode query\n",
        "        query_embedding = self.encode_for_retrieval([query], 'question')\n",
        "\n",
        "        # Compute similarities\n",
        "        similarities = self.compute_similarity_matrix(query_embedding, passage_embeddings)\n",
        "        similarities = similarities.squeeze(0)  # Remove batch dimension\n",
        "\n",
        "        # Get top-k\n",
        "        top_k_scores, top_k_indices = torch.topk(similarities, min(top_k, len(similarities)))\n",
        "\n",
        "        results = []\n",
        "        for i, (score, idx) in enumerate(zip(top_k_scores, top_k_indices)):\n",
        "            results.append((int(idx), float(score), passages[int(idx)]))\n",
        "\n",
        "        return results\n",
        "\n",
        "# Initialize DPR trainer\n",
        "print(\"üß† Initializing Dense Passage Retrieval (DPR) with In-Batch Negatives...\")\n",
        "\n",
        "if DL_LIBRARIES_AVAILABLE:\n",
        "    try:\n",
        "        dpr_trainer = DPRTrainer(\n",
        "            model_name='bert-base-uncased',\n",
        "            projection_dim=768,\n",
        "            learning_rate=2e-5\n",
        "        )\n",
        "        print(\"‚úÖ DPR trainer initialized successfully!\")\n",
        "        print(f\"   üî• Device: {dpr_trainer.device}\")\n",
        "        print(f\"   üìê Projection dim: {dpr_trainer.projection_dim}\")\n",
        "        print(f\"   üîÄ Dual encoders: Question + Passage\")\n",
        "        print(f\"   üéØ Negative sampling strategy: In-batch negatives only\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to initialize DPR trainer: {e}\")\n",
        "        dpr_trainer = None\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Deep learning libraries not available\")\n",
        "    dpr_trainer = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4poNP8RHsNhn",
        "outputId": "4a9146ff-b112-4f7e-8311-20c3b54ba83d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Initializing SPLADE Neural Sparse Retrieval (Correct Implementation)...\n",
            "‚úÖ SPLADE trainer initialized successfully!\n",
            "   üî• Device: cpu\n",
            "   üìö Vocabulary size: 30522\n",
            "   üéØ Key features:\n",
            "      ‚Ä¢ MLM head projection to full vocabulary\n",
            "      ‚Ä¢ Log saturation: log(1 + ReLU(x))\n",
            "      ‚Ä¢ FLOPS regularization (Œª_q=0.06, Œª_d=0.02)\n",
            "      ‚Ä¢ Ranking loss with in-batch negatives\n",
            "      ‚Ä¢ Learns sparse 'bag-of-expanded-words' representations\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Implement SPLADE Neural Sparse Retrieval (Correct Implementation)\n",
        "\n",
        "class SPLADEModel(nn.Module):\n",
        "    \"\"\"\n",
        "    SPLADE (Sparse Lexical And Expansion) Model\n",
        "    Implements the correct SPLADE architecture from Formal et al. 2021\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name='bert-base-uncased'):\n",
        "        super(SPLADEModel, self).__init__()\n",
        "\n",
        "        # Load BERT model with MLM head\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.vocab_size = self.bert.config.vocab_size  # 30,522 for BERT\n",
        "\n",
        "        # MLM head to project back to vocabulary space\n",
        "        self.mlm_head = nn.Linear(self.bert.config.hidden_size, self.vocab_size)\n",
        "\n",
        "        # Initialize MLM head with BERT's original MLM weights if available\n",
        "        try:\n",
        "            bert_mlm = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
        "            if hasattr(bert_mlm, 'cls') and hasattr(bert_mlm.cls, 'predictions'):\n",
        "                self.mlm_head.weight.data = bert_mlm.cls.predictions.transform.dense.weight.data.clone()\n",
        "                self.mlm_head.bias.data = bert_mlm.cls.predictions.bias.data.clone()\n",
        "        except:\n",
        "            pass  # Use default initialization if MLM weights not available\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Forward pass of SPLADE model\n",
        "\n",
        "        Args:\n",
        "            input_ids: Token IDs [batch_size, seq_len]\n",
        "            attention_mask: Attention mask [batch_size, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            Sparse representation [batch_size, vocab_size]\n",
        "        \"\"\"\n",
        "        # Get BERT outputs\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        # Apply MLM head to each token\n",
        "        # Project each token to vocabulary space\n",
        "        token_logits = self.mlm_head(self.dropout(last_hidden_state))  # [batch_size, seq_len, vocab_size]\n",
        "\n",
        "        # Apply ReLU activation (ensure non-negative weights)\n",
        "        token_weights = F.relu(token_logits)  # [batch_size, seq_len, vocab_size]\n",
        "\n",
        "        # Apply log saturation: log(1 + ReLU(x))\n",
        "        token_weights = torch.log(1 + token_weights)  # [batch_size, seq_len, vocab_size]\n",
        "\n",
        "        # Apply attention mask to ignore padded tokens\n",
        "        attention_mask_expanded = attention_mask.unsqueeze(-1).expand(token_weights.size())\n",
        "        token_weights = token_weights * attention_mask_expanded\n",
        "\n",
        "        # Sum over sequence length to get document/query representation\n",
        "        # This aggregates all token contributions for each vocabulary term\n",
        "        sparse_representation = torch.sum(token_weights, dim=1)  # [batch_size, vocab_size]\n",
        "\n",
        "        return sparse_representation\n",
        "\n",
        "class SPLADETrainer:\n",
        "    \"\"\"\n",
        "    SPLADE trainer with proper ranking loss and FLOPS regularization\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name='bert-base-uncased', learning_rate=5e-6):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Initialize SPLADE model\n",
        "        self.model = SPLADEModel(model_name).to(self.device)\n",
        "\n",
        "        # Tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        # Optimizer (lower learning rate for SPLADE)\n",
        "        self.optimizer = optim.AdamW(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Regularization parameters\n",
        "        self.lambda_q = 0.06  # Query regularization strength\n",
        "        self.lambda_d = 0.02  # Document regularization strength\n",
        "\n",
        "        self.vocab_size = self.model.vocab_size\n",
        "\n",
        "    def encode_batch(self, texts, max_length=512):\n",
        "        \"\"\"\n",
        "        Encode batch of texts to sparse representations\n",
        "        \"\"\"\n",
        "        # Tokenize\n",
        "        encoded = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoded['input_ids'].to(self.device)\n",
        "        attention_mask = encoded['attention_mask'].to(self.device)\n",
        "\n",
        "        # Get sparse representations\n",
        "        sparse_repr = self.model(input_ids, attention_mask)\n",
        "\n",
        "        return sparse_repr\n",
        "\n",
        "    def compute_flops_regularization(self, sparse_repr):\n",
        "        \"\"\"\n",
        "        Compute FLOPS regularization to encourage sparsity\n",
        "\n",
        "        Args:\n",
        "            sparse_repr: Sparse representation [batch_size, vocab_size]\n",
        "\n",
        "        Returns:\n",
        "            FLOPS regularization loss\n",
        "        \"\"\"\n",
        "        # Sum of all non-zero elements (approximates FLOPS)\n",
        "        # This penalizes having many non-zero terms\n",
        "        flops_loss = torch.sum(torch.sum(sparse_repr, dim=0) ** 2)\n",
        "        return flops_loss\n",
        "\n",
        "    def compute_ranking_loss(self, query_repr, pos_doc_repr, neg_doc_repr):\n",
        "        \"\"\"\n",
        "        Compute ranking loss with in-batch negatives\n",
        "\n",
        "        Args:\n",
        "            query_repr: Query sparse representations [batch_size, vocab_size]\n",
        "            pos_doc_repr: Positive document representations [batch_size, vocab_size]\n",
        "            neg_doc_repr: Negative document representations [batch_size, vocab_size]\n",
        "\n",
        "        Returns:\n",
        "            Ranking loss\n",
        "        \"\"\"\n",
        "        # Compute similarities using dot product (sparse * sparse)\n",
        "        pos_scores = torch.sum(query_repr * pos_doc_repr, dim=1)  # [batch_size]\n",
        "        neg_scores = torch.sum(query_repr * neg_doc_repr, dim=1)  # [batch_size]\n",
        "\n",
        "        # Ranking loss: maximize positive scores, minimize negative scores\n",
        "        ranking_loss = torch.mean(torch.maximum(torch.zeros_like(pos_scores),\n",
        "                                               1.0 - pos_scores + neg_scores))\n",
        "\n",
        "        return ranking_loss\n",
        "\n",
        "    def train_step(self, queries, positive_docs, negative_docs):\n",
        "        \"\"\"\n",
        "        Single training step with ranking loss and FLOPS regularization\n",
        "\n",
        "        Args:\n",
        "            queries: List of query strings\n",
        "            positive_docs: List of positive document strings\n",
        "            negative_docs: List of negative document strings\n",
        "\n",
        "        Returns:\n",
        "            Total loss, ranking loss, regularization loss\n",
        "        \"\"\"\n",
        "        # Encode queries and documents\n",
        "        query_repr = self.encode_batch(queries)\n",
        "        pos_doc_repr = self.encode_batch(positive_docs)\n",
        "        neg_doc_repr = self.encode_batch(negative_docs)\n",
        "\n",
        "        # Compute ranking loss\n",
        "        ranking_loss = self.compute_ranking_loss(query_repr, pos_doc_repr, neg_doc_repr)\n",
        "\n",
        "        # Compute FLOPS regularization\n",
        "        query_flops = self.compute_flops_regularization(query_repr)\n",
        "        doc_flops = self.compute_flops_regularization(pos_doc_repr)\n",
        "\n",
        "        # Total regularization loss\n",
        "        reg_loss = self.lambda_q * query_flops + self.lambda_d * doc_flops\n",
        "\n",
        "        # Total loss\n",
        "        total_loss = ranking_loss + reg_loss\n",
        "\n",
        "        # Backward pass\n",
        "        self.optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return total_loss.item(), ranking_loss.item(), reg_loss.item()\n",
        "\n",
        "    # Modify train_epoch to perform comprehensive validation and save metrics\n",
        "    def train_epoch(self, train_data: List[Tuple[str, str, str]], batch_size: int, epoch: int, val_questions: List[str], val_answers: List[str]):\n",
        "        \"\"\"\n",
        "        Train for one epoch with comprehensive validation, and save checkpoint with metrics\n",
        "\n",
        "        Args:\n",
        "            train_data: List of (query, positive_doc, negative_doc) tuples\n",
        "            batch_size: Training batch size\n",
        "            epoch: Current epoch number (for logging and checkpointing)\n",
        "            val_questions: List of validation questions\n",
        "            val_answers: List of validation answers\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with comprehensive training and validation metrics for the epoch\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "\n",
        "        total_loss = 0\n",
        "        total_ranking_loss = 0\n",
        "        total_reg_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        # Shuffle training data\n",
        "        random.shuffle(train_data)\n",
        "\n",
        "        for i in tqdm(range(0, len(train_data), batch_size), desc=f\"Epoch {epoch+1} Training SPLADE\"):\n",
        "            batch_data = train_data[i:i+batch_size]\n",
        "\n",
        "            # Extract queries, positive docs, and negative docs\n",
        "            queries = [item[0] for item in batch_data]\n",
        "            positive_docs = [item[1] for item in batch_data]\n",
        "            negative_docs = [item[2] for item in batch_data]\n",
        "\n",
        "            # Training step\n",
        "            loss, ranking_loss, reg_loss = self.train_step(queries, positive_docs, negative_docs)\n",
        "\n",
        "            total_loss += loss\n",
        "            total_ranking_loss += ranking_loss\n",
        "            total_reg_loss += reg_loss\n",
        "            num_batches += 1\n",
        "\n",
        "            # Log batch loss to wandb\n",
        "            if wandb.run:\n",
        "                wandb.log({\n",
        "                    \"splade/batch_total_loss\": loss,\n",
        "                    \"splade/batch_ranking_loss\": ranking_loss,\n",
        "                    \"splade/batch_reg_loss\": reg_loss\n",
        "                }, step=epoch * (len(train_data) // batch_size) + num_batches)\n",
        "\n",
        "        avg_total_loss = total_loss / num_batches if num_batches > 0 else 0\n",
        "        avg_ranking_loss = total_ranking_loss / num_batches if num_batches > 0 else 0\n",
        "        avg_reg_loss = total_reg_loss / num_batches if num_batches > 0 else 0\n",
        "\n",
        "        # Comprehensive Validation\n",
        "        print(f\"   ‚Ä¢ Performing comprehensive validation...\")\n",
        "        val_subset_size = min(50, len(val_questions))  # Increased validation subset size for better metrics\n",
        "        val_doc_representations = self.encode_for_retrieval(val_answers[:val_subset_size])\n",
        "\n",
        "        # Initialize metrics tracking\n",
        "        top_k_accuracies = {1: 0, 5: 0, 10: 0, 20: 0}\n",
        "        val_predictions = []\n",
        "\n",
        "        # Evaluate validation set\n",
        "        for i, question in enumerate(val_questions[:val_subset_size]):\n",
        "            results_list = self.retrieve(question, val_doc_representations, val_answers[:val_subset_size], top_k=20)\n",
        "\n",
        "            if results_list:\n",
        "                # Get top-1 prediction for QA metrics\n",
        "                best_answer = results_list[0][2]\n",
        "                val_predictions.append(best_answer)\n",
        "\n",
        "                # Calculate top-k accuracies\n",
        "                correct_answer = val_answers[i]\n",
        "                retrieved_answers = [r[2] for r in results_list]\n",
        "\n",
        "                for k in [1, 5, 10, 20]:\n",
        "                    if correct_answer in retrieved_answers[:k]:\n",
        "                        top_k_accuracies[k] += 1\n",
        "            else:\n",
        "                val_predictions.append(\"\")\n",
        "\n",
        "        # Calculate final metrics\n",
        "        for k in top_k_accuracies:\n",
        "            top_k_accuracies[k] = top_k_accuracies[k] / val_subset_size if val_subset_size > 0 else 0.0\n",
        "\n",
        "        # QA performance metrics (F1 and Exact Match)\n",
        "        from collections import Counter\n",
        "        import re\n",
        "\n",
        "        def normalize_answer(text):\n",
        "            text = text.lower()\n",
        "            text = re.sub(r'[^\\w\\s]', '', text)\n",
        "            text = ' '.join(text.split())\n",
        "            return text\n",
        "\n",
        "        def exact_match(prediction, ground_truth):\n",
        "            return float(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "        def f1_score(prediction, ground_truth):\n",
        "            pred_tokens = normalize_answer(prediction).split()\n",
        "            gt_tokens = normalize_answer(ground_truth).split()\n",
        "\n",
        "            if len(pred_tokens) == 0 and len(gt_tokens) == 0:\n",
        "                return 1.0\n",
        "            if len(pred_tokens) == 0 or len(gt_tokens) == 0:\n",
        "                return 0.0\n",
        "\n",
        "            common_tokens = Counter(pred_tokens) & Counter(gt_tokens)\n",
        "            num_same = sum(common_tokens.values())\n",
        "\n",
        "            if num_same == 0:\n",
        "                return 0.0\n",
        "\n",
        "            precision = num_same / len(pred_tokens)\n",
        "            recall = num_same / len(gt_tokens)\n",
        "\n",
        "            return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "        # Calculate QA metrics\n",
        "        exact_matches = [exact_match(pred, gt) for pred, gt in zip(val_predictions, val_answers[:val_subset_size])]\n",
        "        f1_scores = [f1_score(pred, gt) for pred, gt in zip(val_predictions, val_answers[:val_subset_size])]\n",
        "\n",
        "        val_exact_match = np.mean(exact_matches) if exact_matches else 0.0\n",
        "        val_f1 = np.mean(f1_scores) if f1_scores else 0.0\n",
        "\n",
        "        print(f\"   ‚Ä¢ Validation Results (subset size: {val_subset_size}):\")\n",
        "        print(f\"     - Top-1 accuracy: {top_k_accuracies[1]:.3f}\")\n",
        "        print(f\"     - Top-5 accuracy: {top_k_accuracies[5]:.3f}\")\n",
        "        print(f\"     - Top-10 accuracy: {top_k_accuracies[10]:.3f}\")\n",
        "        print(f\"     - Top-20 accuracy: {top_k_accuracies[20]:.3f}\")\n",
        "        print(f\"     - Exact Match: {val_exact_match:.3f}\")\n",
        "        print(f\"     - F1 Score: {val_f1:.3f}\")\n",
        "\n",
        "        # Log comprehensive epoch metrics to wandb\n",
        "        if wandb.run:\n",
        "            wandb.log({\n",
        "                \"splade/epoch_total_loss\": avg_total_loss,\n",
        "                \"splade/epoch_ranking_loss\": avg_ranking_loss,\n",
        "                \"splade/epoch_reg_loss\": avg_reg_loss,\n",
        "                \"splade/val_top_1_accuracy\": top_k_accuracies[1],\n",
        "                \"splade/val_top_5_accuracy\": top_k_accuracies[5],\n",
        "                \"splade/val_top_10_accuracy\": top_k_accuracies[10],\n",
        "                \"splade/val_top_20_accuracy\": top_k_accuracies[20],\n",
        "                \"splade/val_exact_match\": val_exact_match,\n",
        "                \"splade/val_f1\": val_f1\n",
        "            }, step=epoch)\n",
        "\n",
        "        # Save checkpoint after each epoch with comprehensive metrics\n",
        "        checkpoint_dir = \"splade_checkpoints\"\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f\"splade_epoch_{epoch+1}.pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'total_loss': avg_total_loss,\n",
        "            'ranking_loss': avg_ranking_loss,\n",
        "            'reg_loss': avg_reg_loss,\n",
        "            'val_top_1_accuracy': top_k_accuracies[1],\n",
        "            'val_top_5_accuracy': top_k_accuracies[5],\n",
        "            'val_top_10_accuracy': top_k_accuracies[10],\n",
        "            'val_top_20_accuracy': top_k_accuracies[20],\n",
        "            'val_exact_match': val_exact_match,\n",
        "            'val_f1': val_f1,\n",
        "            'val_subset_size': val_subset_size\n",
        "        }, checkpoint_path)\n",
        "        print(f\"Checkpoint saved to {checkpoint_path}\")\n",
        "\n",
        "        # Log checkpoint artifact to wandb\n",
        "        if wandb.run:\n",
        "            artifact = wandb.Artifact(f'splade-model-epoch-{epoch+1}', type='model')\n",
        "            artifact.add_file(checkpoint_path)\n",
        "            wandb.log_artifact(artifact)\n",
        "\n",
        "        # Return comprehensive validation metrics\n",
        "        epoch_metrics = {\n",
        "            'total_loss': avg_total_loss,\n",
        "            'ranking_loss': avg_ranking_loss,\n",
        "            'reg_loss': avg_reg_loss,\n",
        "            'top_1_accuracy': top_k_accuracies[1],\n",
        "            'top_5_accuracy': top_k_accuracies[5],\n",
        "            'top_10_accuracy': top_k_accuracies[10],\n",
        "            'top_20_accuracy': top_k_accuracies[20],\n",
        "            'exact_match': val_exact_match,\n",
        "            'f1': val_f1,\n",
        "            'val_subset_size': val_subset_size\n",
        "        }\n",
        "\n",
        "        return epoch_metrics\n",
        "\n",
        "\n",
        "    def encode_for_retrieval(self, texts, batch_size=32):\n",
        "        \"\"\"\n",
        "        Encode texts for retrieval (inference mode)\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        all_representations = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, len(texts), batch_size):\n",
        "                batch_texts = texts[i:i+batch_size]\n",
        "                sparse_repr = self.encode_batch(batch_texts)\n",
        "                all_representations.append(sparse_repr)\n",
        "\n",
        "        return torch.cat(all_representations, dim=0)\n",
        "\n",
        "    def retrieve(self, query, document_representations, documents, top_k=5):\n",
        "        \"\"\"\n",
        "        Retrieve top-k documents for a query using sparse representations\n",
        "\n",
        "        Args:\n",
        "            query: Query string\n",
        "            document_representations: Pre-computed document sparse representations\n",
        "            documents: List of document strings\n",
        "            top_k: Number of documents to retrieve\n",
        "\n",
        "        Returns:\n",
        "            List of (doc_idx, score, doc_text) tuples\n",
        "        \"\"\"\n",
        "        # Encode query\n",
        "        query_repr = self.encode_for_retrieval([query])\n",
        "\n",
        "        # Compute similarities (dot product for sparse vectors)\n",
        "        similarities = torch.sum(query_repr * document_representations, dim=1)\n",
        "\n",
        "        # Get top-k\n",
        "        top_k_scores, top_k_indices = torch.topk(similarities, min(top_k, len(similarities)))\n",
        "\n",
        "        results = []\n",
        "        for score, idx in zip(top_k_scores, top_k_indices):\n",
        "            results.append((int(idx), float(score), documents[int(idx)]))\n",
        "\n",
        "        return results\n",
        "\n",
        "    def get_sparse_statistics(self, sparse_repr):\n",
        "        \"\"\"\n",
        "        Get statistics about sparsity of representations\n",
        "        \"\"\"\n",
        "        # Count non-zero elements\n",
        "        non_zero_count = torch.sum(sparse_repr > 0, dim=1).float()\n",
        "        sparsity = 1.0 - (non_zero_count / self.vocab_size)\n",
        "\n",
        "        return {\n",
        "            'avg_non_zero_terms': torch.mean(non_zero_count).item(),\n",
        "            'avg_sparsity': torch.mean(sparsity).item(),\n",
        "            'max_weight': torch.max(sparse_repr).item(),\n",
        "            'avg_weight': torch.mean(sparse_repr[sparse_repr > 0]).item()\n",
        "        }\n",
        "\n",
        "# Initialize SPLADE trainer\n",
        "print(\"üîç Initializing SPLADE Neural Sparse Retrieval (Correct Implementation)...\")\n",
        "\n",
        "if DL_LIBRARIES_AVAILABLE:\n",
        "    try:\n",
        "        splade_trainer = SPLADETrainer(\n",
        "            model_name='bert-base-uncased',\n",
        "            learning_rate=5e-6  # Lower learning rate for SPLADE\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ SPLADE trainer initialized successfully!\")\n",
        "        print(f\"   üî• Device: {splade_trainer.device}\")\n",
        "        print(f\"   üìö Vocabulary size: {splade_trainer.vocab_size}\")\n",
        "        print(f\"   üéØ Key features:\")\n",
        "        print(f\"      ‚Ä¢ MLM head projection to full vocabulary\")\n",
        "        print(f\"      ‚Ä¢ Log saturation: log(1 + ReLU(x))\")\n",
        "        print(f\"      ‚Ä¢ FLOPS regularization (Œª_q={splade_trainer.lambda_q}, Œª_d={splade_trainer.lambda_d})\")\n",
        "        print(f\"      ‚Ä¢ Ranking loss with in-batch negatives\")\n",
        "        print(f\"      ‚Ä¢ Learns sparse 'bag-of-expanded-words' representations\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to initialize SPLADE trainer: {e}\")\n",
        "        splade_trainer = None\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Deep learning libraries not available\")\n",
        "    splade_trainer = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUseOB3eZW1h",
        "outputId": "7dec85a2-7887-4f43-8077-bd5692666b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Deep learning evaluation framework ready!\n",
            "   üìä Metrics: Exact Match, F1 Score\n",
            "   üéØ Focus: Retrieval performance for medical domain QA\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Define Evaluation Framework for Deep Learning Methods\n",
        "\n",
        "class DeepLearningEvaluator:\n",
        "    \"\"\"Evaluation framework for deep learning retrieval methods\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.metrics = {}\n",
        "\n",
        "    def normalize_answer(self, text: str) -> str:\n",
        "        \"\"\"Normalize answer text for comparison\"\"\"\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        text = ' '.join(text.split())\n",
        "        return text\n",
        "\n",
        "    def exact_match(self, prediction: str, ground_truth: str) -> float:\n",
        "        \"\"\"Calculate exact match score\"\"\"\n",
        "        return float(self.normalize_answer(prediction) == self.normalize_answer(ground_truth))\n",
        "\n",
        "    def f1_score(self, prediction: str, ground_truth: str) -> float:\n",
        "        \"\"\"Calculate F1 score at token level\"\"\"\n",
        "        pred_tokens = self.normalize_answer(prediction).split()\n",
        "        gt_tokens = self.normalize_answer(ground_truth).split()\n",
        "\n",
        "        if len(pred_tokens) == 0 and len(gt_tokens) == 0:\n",
        "            return 1.0\n",
        "        if len(pred_tokens) == 0 or len(gt_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        common_tokens = Counter(pred_tokens) & Counter(gt_tokens)\n",
        "        num_same = sum(common_tokens.values())\n",
        "\n",
        "        if num_same == 0:\n",
        "            return 0.0\n",
        "\n",
        "        precision = num_same / len(pred_tokens)\n",
        "        recall = num_same / len(gt_tokens)\n",
        "\n",
        "        return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    def evaluate_qa_performance(self, predictions: List[str], ground_truths: List[str]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Evaluate QA performance using traditional metrics\n",
        "\n",
        "        Args:\n",
        "            predictions: List of predicted answers\n",
        "            ground_truths: List of ground truth answers\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of QA evaluation metrics\n",
        "        \"\"\"\n",
        "        if len(predictions) != len(ground_truths):\n",
        "            raise ValueError(\"Predictions and ground truths must have same length\")\n",
        "\n",
        "        exact_matches = [self.exact_match(pred, gt) for pred, gt in zip(predictions, ground_truths)]\n",
        "        f1_scores = [self.f1_score(pred, gt) for pred, gt in zip(predictions, ground_truths)]\n",
        "\n",
        "        return {\n",
        "            'exact_match': np.mean(exact_matches),\n",
        "            'f1': np.mean(f1_scores),\n",
        "            'count': len(predictions)\n",
        "        }\n",
        "\n",
        "# Initialize evaluator\n",
        "evaluator = DeepLearningEvaluator()\n",
        "print(\"‚úÖ Deep learning evaluation framework ready!\")\n",
        "print(\"   üìä Metrics: Exact Match, F1 Score\")\n",
        "print(\"   üéØ Focus: Retrieval performance for medical domain QA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SvnJh-OpZW1i",
        "outputId": "754a56a7-6106-4418-a43b-ca611ec68648",
        "tags": [
          "DPR_Training"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Training and Evaluating Deep Learning Methods with Proper Dataset Splits\n",
            "================================================================================\n",
            "üéØ TRAINING PHASE\n",
            "----------------------------------------\n",
            "üìä Training data preparation:\n",
            "   ‚Ä¢ Full training set: 1,606 QA pairs\n",
            "   ‚Ä¢ Training subset: 1,606 QA pairs (for efficiency)\n",
            "   ‚Ä¢ Validation set: 201 QA pairs\n",
            "   ‚Ä¢ Test set: 201 QA pairs\n",
            "üéØ Corpus for negative sampling: 1,606 passages\n",
            "\n",
            "üß† DENSE PASSAGE RETRIEVAL (DPR) TRAINING & EVALUATION\n",
            "------------------------------------------------------------\n",
            "Attempting to load model from wandb artifact: dpr-model-epoch-1:v0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250723_051507-awp0733m</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jglppk/Domain%20QA/runs/awp0733m' target=\"_blank\">warm-flower-31</a></strong> to <a href='https://wandb.ai/jglppk/Domain%20QA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jglppk/Domain%20QA' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jglppk/Domain%20QA/runs/awp0733m' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA/runs/awp0733m</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dpr-model-epoch-1:v0, 2510.82MB. 1 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 0:0:15.1 (166.3MB/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Successfully loaded checkpoint from epoch 0. Resuming training from epoch 1.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">warm-flower-31</strong> at: <a href='https://wandb.ai/jglppk/Domain%20QA/runs/awp0733m' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA/runs/awp0733m</a><br> View project at: <a href='https://wandb.ai/jglppk/Domain%20QA' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250723_051507-awp0733m/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ DPR Training configuration:\n",
            "   ‚Ä¢ Epochs: 6\n",
            "   ‚Ä¢ Batch size: 8\n",
            "   ‚Ä¢ Training pairs: 1,606\n",
            "   ‚Ä¢ Negative sampling: In-batch negatives only\n",
            "   ‚Ä¢ Starting epoch: 1\n",
            "\n",
            "üèÉ Training DPR...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250723_051528-a6v7nn9o</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jglppk/Domain%20QA/runs/a6v7nn9o' target=\"_blank\">DPR Training</a></strong> to <a href='https://wandb.ai/jglppk/Domain%20QA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jglppk/Domain%20QA' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jglppk/Domain%20QA/runs/a6v7nn9o' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA/runs/a6v7nn9o</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Checking for existing dataset splits in wandb...\n",
            "‚úÖ Found existing dataset splits, loading from wandb:\n",
            "   ‚Ä¢ Using artifact: covid-qa-splits:latest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚Ä¢ Training set: 1,606 QA pairs\n",
            "   ‚Ä¢ Validation set: 201 QA pairs\n",
            "   ‚Ä¢ Test set: 201 QA pairs\n",
            "Logged dataset size and hyperparameters to wandb.\n",
            "\n",
            "üìÖ Epoch 2/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training DPR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [1:01:07<00:00, 18.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚Ä¢ Performing comprehensive validation...\n",
            "   ‚Ä¢ Validation Results (subset size: 50):\n",
            "     - Top-1 accuracy: 0.420\n",
            "     - Top-5 accuracy: 0.920\n",
            "     - Top-10 accuracy: 0.960\n",
            "     - Top-20 accuracy: 0.980\n",
            "     - Exact Match: 0.420\n",
            "     - F1 Score: 0.535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved to dpr_checkpoints/dpr_epoch_2.pth\n",
            "   ‚Ä¢ Training loss: 0.5116\n",
            "   ‚Ä¢ Validation Results:\n",
            "     - Top-1 accuracy: 0.420\n",
            "     - Top-5 accuracy: 0.920\n",
            "     - Top-10 accuracy: 0.960\n",
            "     - Top-20 accuracy: 0.980\n",
            "     - Exact Match: 0.420\n",
            "     - F1 Score: 0.535\n",
            "   ‚Ä¢ Memory usage after epoch 2: 21358.45 MB\n",
            "\n",
            "üìÖ Epoch 3/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training DPR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [1:00:47<00:00, 18.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚Ä¢ Performing comprehensive validation...\n",
            "   ‚Ä¢ Validation Results (subset size: 50):\n",
            "     - Top-1 accuracy: 0.520\n",
            "     - Top-5 accuracy: 0.980\n",
            "     - Top-10 accuracy: 0.980\n",
            "     - Top-20 accuracy: 0.980\n",
            "     - Exact Match: 0.520\n",
            "     - F1 Score: 0.611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 601. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved to dpr_checkpoints/dpr_epoch_3.pth\n",
            "   ‚Ä¢ Training loss: 0.3490\n",
            "   ‚Ä¢ Validation Results:\n",
            "     - Top-1 accuracy: 0.520\n",
            "     - Top-5 accuracy: 0.980\n",
            "     - Top-10 accuracy: 0.980\n",
            "     - Top-20 accuracy: 0.980\n",
            "     - Exact Match: 0.520\n",
            "     - F1 Score: 0.611\n",
            "   ‚Ä¢ Memory usage after epoch 3: 22185.36 MB\n",
            "\n",
            "üìÖ Epoch 4/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training DPR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [1:03:50<00:00, 19.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚Ä¢ Performing comprehensive validation...\n",
            "   ‚Ä¢ Validation Results (subset size: 50):\n",
            "     - Top-1 accuracy: 0.500\n",
            "     - Top-5 accuracy: 0.980\n",
            "     - Top-10 accuracy: 0.980\n",
            "     - Top-20 accuracy: 0.980\n",
            "     - Exact Match: 0.500\n",
            "     - F1 Score: 0.591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 801. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved to dpr_checkpoints/dpr_epoch_4.pth\n",
            "   ‚Ä¢ Training loss: 0.2620\n",
            "   ‚Ä¢ Validation Results:\n",
            "     - Top-1 accuracy: 0.500\n",
            "     - Top-5 accuracy: 0.980\n",
            "     - Top-10 accuracy: 0.980\n",
            "     - Top-20 accuracy: 0.980\n",
            "     - Exact Match: 0.500\n",
            "     - F1 Score: 0.591\n",
            "   ‚Ä¢ Memory usage after epoch 4: 22547.08 MB\n",
            "\n",
            "üìÖ Epoch 5/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training DPR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [1:03:16<00:00, 18.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚Ä¢ Performing comprehensive validation...\n",
            "   ‚Ä¢ Validation Results (subset size: 50):\n",
            "     - Top-1 accuracy: 0.600\n",
            "     - Top-5 accuracy: 0.980\n",
            "     - Top-10 accuracy: 0.980\n",
            "     - Top-20 accuracy: 0.980\n",
            "     - Exact Match: 0.600\n",
            "     - F1 Score: 0.668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 1001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved to dpr_checkpoints/dpr_epoch_5.pth\n",
            "   ‚Ä¢ Training loss: 0.2126\n",
            "   ‚Ä¢ Validation Results:\n",
            "     - Top-1 accuracy: 0.600\n",
            "     - Top-5 accuracy: 0.980\n",
            "     - Top-10 accuracy: 0.980\n",
            "     - Top-20 accuracy: 0.980\n",
            "     - Exact Match: 0.600\n",
            "     - F1 Score: 0.668\n",
            "   ‚Ä¢ Memory usage after epoch 5: 22416.53 MB\n",
            "\n",
            "üìÖ Epoch 6/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training DPR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [1:01:23<00:00, 18.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚Ä¢ Performing comprehensive validation...\n",
            "   ‚Ä¢ Validation Results (subset size: 50):\n",
            "     - Top-1 accuracy: 0.580\n",
            "     - Top-5 accuracy: 0.940\n",
            "     - Top-10 accuracy: 0.980\n",
            "     - Top-20 accuracy: 1.000\n",
            "     - Exact Match: 0.580\n",
            "     - F1 Score: 0.657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 1201. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved to dpr_checkpoints/dpr_epoch_6.pth\n",
            "   ‚Ä¢ Training loss: 0.2022\n",
            "   ‚Ä¢ Validation Results:\n",
            "     - Top-1 accuracy: 0.580\n",
            "     - Top-5 accuracy: 0.940\n",
            "     - Top-10 accuracy: 0.980\n",
            "     - Top-20 accuracy: 1.000\n",
            "     - Exact Match: 0.580\n",
            "     - F1 Score: 0.657\n",
            "   ‚Ä¢ Memory usage after epoch 6: 21917.97 MB\n",
            "\n",
            "üìÖ Epoch 7/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training DPR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [1:00:30<00:00, 18.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚Ä¢ Performing comprehensive validation...\n",
            "   ‚Ä¢ Validation Results (subset size: 50):\n",
            "     - Top-1 accuracy: 0.580\n",
            "     - Top-5 accuracy: 0.960\n",
            "     - Top-10 accuracy: 0.980\n",
            "     - Top-20 accuracy: 1.000\n",
            "     - Exact Match: 0.580\n",
            "     - F1 Score: 0.663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 1401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved to dpr_checkpoints/dpr_epoch_7.pth\n",
            "   ‚Ä¢ Training loss: 0.1712\n",
            "   ‚Ä¢ Validation Results:\n",
            "     - Top-1 accuracy: 0.580\n",
            "     - Top-5 accuracy: 0.960\n",
            "     - Top-10 accuracy: 0.980\n",
            "     - Top-20 accuracy: 1.000\n",
            "     - Exact Match: 0.580\n",
            "     - F1 Score: 0.663\n",
            "   ‚Ä¢ Memory usage after epoch 7: 22172.33 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dataset/test_size</td><td>‚ñÅ</td></tr><tr><td>dataset/total_size</td><td>‚ñÅ</td></tr><tr><td>dataset/train_size</td><td>‚ñÅ</td></tr><tr><td>dataset/val_size</td><td>‚ñÅ</td></tr><tr><td>dpr/batch_loss</td><td>‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÑ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dataset/loaded_from_wandb</td><td>True</td></tr><tr><td>dataset/test_size</td><td>201</td></tr><tr><td>dataset/total_size</td><td>2008</td></tr><tr><td>dataset/train_size</td><td>1606</td></tr><tr><td>dataset/val_size</td><td>201</td></tr><tr><td>dpr/batch_loss</td><td>0.25357</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">DPR Training</strong> at: <a href='https://wandb.ai/jglppk/Domain%20QA/runs/a6v7nn9o' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA/runs/a6v7nn9o</a><br> View project at: <a href='https://wandb.ai/jglppk/Domain%20QA' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA</a><br>Synced 5 W&B file(s), 0 media file(s), 12 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250723_051528-a6v7nn9o/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ DPR training completed!\n",
            "\n",
            "üîç Evaluating DPR on test set...\n",
            "   ‚Ä¢ Test set size: 201 QA pairs\n",
            "‚úÖ DPR Test Results:\n",
            "   ‚Ä¢ Test set size: 201\n",
            "   ‚Ä¢ Top-1 accuracy: 0.353\n",
            "   ‚Ä¢ Top-5 accuracy: 0.692\n",
            "   ‚Ä¢ Top-10 accuracy: 0.896\n",
            "   ‚Ä¢ Top-20 accuracy: 0.950\n",
            "   ‚Ä¢ QA Exact Match: 0.353\n",
            "   ‚Ä¢ QA F1 Score: 0.454\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250723_113406-e4b9ozxg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jglppk/Domain%20QA/runs/e4b9ozxg' target=\"_blank\">DPR Training</a></strong> to <a href='https://wandb.ai/jglppk/Domain%20QA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jglppk/Domain%20QA' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jglppk/Domain%20QA/runs/e4b9ozxg' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA/runs/e4b9ozxg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dpr/test_exact_match</td><td>‚ñÅ</td></tr><tr><td>dpr/test_f1</td><td>‚ñÅ</td></tr><tr><td>dpr/test_top_10_accuracy</td><td>‚ñÅ</td></tr><tr><td>dpr/test_top_1_accuracy</td><td>‚ñÅ</td></tr><tr><td>dpr/test_top_20_accuracy</td><td>‚ñÅ</td></tr><tr><td>dpr/test_top_5_accuracy</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dpr/test_exact_match</td><td>0.35323</td></tr><tr><td>dpr/test_f1</td><td>0.4543</td></tr><tr><td>dpr/test_top_10_accuracy</td><td>0.89552</td></tr><tr><td>dpr/test_top_1_accuracy</td><td>0.35323</td></tr><tr><td>dpr/test_top_20_accuracy</td><td>0.95025</td></tr><tr><td>dpr/test_top_5_accuracy</td><td>0.69154</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">DPR Training</strong> at: <a href='https://wandb.ai/jglppk/Domain%20QA/runs/e4b9ozxg' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA/runs/e4b9ozxg</a><br> View project at: <a href='https://wandb.ai/jglppk/Domain%20QA' target=\"_blank\">https://wandb.ai/jglppk/Domain%20QA</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250723_113406-e4b9ozxg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä DPR Epoch-by-Epoch Summary:\n",
            "Epoch  Loss     Top-1    Top-5    Top-10   Top-20   EM       F1      \n",
            "-----------------------------------------------------------------\n",
            "2      0.5116   0.420    0.920    0.960    0.980    0.420    0.535   \n",
            "3      0.3490   0.520    0.980    0.980    0.980    0.520    0.611   \n",
            "4      0.2620   0.500    0.980    0.980    0.980    0.500    0.591   \n",
            "5      0.2126   0.600    0.980    0.980    0.980    0.600    0.668   \n",
            "6      0.2022   0.580    0.940    0.980    1.000    0.580    0.657   \n",
            "7      0.1712   0.580    0.960    0.980    1.000    0.580    0.663   \n"
          ]
        }
      ],
      "source": [
        "# Step 5: Train and Evaluate Deep Learning Methods with Proper Splits with DPR\n",
        "print(\"üöÄ Training and Evaluating Deep Learning Methods with Proper Dataset Splits\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize results storage\n",
        "results = {}\n",
        "\n",
        "# ===== TRAINING PHASE =====\n",
        "print(\"üéØ TRAINING PHASE\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Prepare training data (subset for efficiency)\n",
        "# Use full training set if using dummy data to facilitate negative sampling\n",
        "train_subset_size = len(train_questions) # Reduced training subset size\n",
        "\n",
        "train_subset_questions = train_questions[:train_subset_size]\n",
        "train_subset_answers = train_answers[:train_subset_size]\n",
        "\n",
        "print(f\"üìä Training data preparation:\")\n",
        "print(f\"   ‚Ä¢ Full training set: {len(train_questions):,} QA pairs\")\n",
        "print(f\"   ‚Ä¢ Training subset: {train_subset_size:,} QA pairs (for efficiency)\")\n",
        "print(f\"   ‚Ä¢ Validation set: {len(val_questions):,} QA pairs\")\n",
        "print(f\"   ‚Ä¢ Test set: {len(test_questions):,} QA pairs\")\n",
        "\n",
        "# Create corpus for negative sampling (using training answers only)\n",
        "corpus_for_negatives = train_answers.copy()\n",
        "print(f\"üéØ Corpus for negative sampling: {len(corpus_for_negatives):,} passages\")\n",
        "\n",
        "# ===== DPR TRAINING AND EVALUATION =====\n",
        "print(f\"\\nüß† DENSE PASSAGE RETRIEVAL (DPR) TRAINING & EVALUATION\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "if DL_LIBRARIES_AVAILABLE and dpr_trainer is not None:\n",
        "    try:\n",
        "        # Prepare training data\n",
        "        train_data = [(q, a) for q, a in zip(train_subset_questions, train_subset_answers)]\n",
        "\n",
        "        # Training parameters\n",
        "        num_epochs =  6 # Reduced for resource efficiency\n",
        "        batch_size = 8 # Reduced for resource efficiency\n",
        "\n",
        "        # --- Start: Added code for loading from wandb checkpoint ---\n",
        "        load_from_wandb = True  # Set to True to load from wandb\n",
        "        wandb_project = \"Domain QA\" # Replace with your project name\n",
        "        wandb_artifact_name = \"dpr-model-epoch-1:v0\" # Replace with your artifact name and version\n",
        "\n",
        "        start_epoch = 0 # Default start epoch\n",
        "\n",
        "        if load_from_wandb:\n",
        "            print(f\"Attempting to load model from wandb artifact: {wandb_artifact_name}\")\n",
        "            try:\n",
        "                # Use wandb.init() as a context manager for loading as well\n",
        "                with wandb.init(project=wandb_project, resume=True) as run:\n",
        "                    artifact = run.use_artifact(wandb_artifact_name, type='model')\n",
        "                    artifact_dir = artifact.download()\n",
        "                    checkpoint_path = os.path.join(artifact_dir, f\"dpr_epoch_{wandb_artifact_name.split(':')[0].split('-')[-1]}.pth\") # Assuming filename format\n",
        "\n",
        "                    checkpoint = torch.load(checkpoint_path)\n",
        "                    dpr_trainer.question_encoder.load_state_dict(checkpoint['question_encoder_state_dict'])\n",
        "                    dpr_trainer.passage_encoder.load_state_dict(checkpoint['passage_encoder_state_dict'])\n",
        "                    dpr_trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                    start_epoch = checkpoint['epoch'] + 1 # Start from the epoch after the loaded one\n",
        "                    print(f\"‚úÖ Successfully loaded checkpoint from epoch {checkpoint['epoch']}. Resuming training from epoch {start_epoch}.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to load checkpoint from wandb: {e}\")\n",
        "                print(\"Starting training from scratch.\")\n",
        "                start_epoch = 0\n",
        "        # --- End: Added code for loading from wandb checkpoint ---\n",
        "\n",
        "        print(f\"üéØ DPR Training configuration:\")\n",
        "        print(f\"   ‚Ä¢ Epochs: {num_epochs}\")\n",
        "        print(f\"   ‚Ä¢ Batch size: {batch_size}\")\n",
        "        print(f\"   ‚Ä¢ Training pairs: {len(train_data):,}\")\n",
        "        print(f\"   ‚Ä¢ Negative sampling: In-batch negatives only\") # Updated description\n",
        "        print(f\"   ‚Ä¢ Starting epoch: {start_epoch}\")\n",
        "\n",
        "        # Training loop with comprehensive epoch-by-epoch metrics tracking\n",
        "        print(f\"\\nüèÉ Training DPR...\")\n",
        "        training_losses = []\n",
        "        epoch_metrics_history = []  # Store all epoch metrics\n",
        "\n",
        "        # Use wandb.init() as a context manager for training\n",
        "        with wandb.init(project=\"Domain QA\", name=\"DPR Training\", config={\n",
        "            \"dataset_train_size\": len(train_data),\n",
        "            \"dataset_val_size\": len(val_questions),\n",
        "            \"dataset_test_size\": len(test_questions),\n",
        "            \"model_name\": 'bert-base-uncased', # Assuming this is the model name\n",
        "            \"projection_dim\": dpr_trainer.projection_dim,\n",
        "            \"learning_rate\": dpr_trainer.optimizer.param_groups[0]['lr'], # Get current LR\n",
        "            \"num_epochs\": num_epochs,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"negative_sampling\": \"in-batch only\"\n",
        "        }) as run:\n",
        "            # ===== DATASET SPLIT HANDLING WITHIN TRAINING RUN =====\n",
        "            print(\"üìä Checking for existing dataset splits in wandb...\")\n",
        "            dataset_loaded_from_wandb = False\n",
        "            dataset_artifact_name = \"covid-qa-splits\"  # Standard artifact name\n",
        "\n",
        "            # Check if artifact already exists and load or create\n",
        "            try:\n",
        "                existing_artifact = run.use_artifact(f\"{dataset_artifact_name}:latest\", type=\"dataset_split\")\n",
        "                print(f\"‚úÖ Found existing dataset splits, loading from wandb:\")\n",
        "                print(f\"   ‚Ä¢ Using artifact: {existing_artifact.name}\")\n",
        "\n",
        "                # Load the dataset splits from wandb tables\n",
        "                train_table = existing_artifact.get(\"train_data_frame\")\n",
        "                val_table = existing_artifact.get(\"val_data_frame\")\n",
        "                test_table = existing_artifact.get(\"test_data_frame\")\n",
        "\n",
        "                # Convert back to lists\n",
        "                train_df_loaded = train_table.get_dataframe()\n",
        "                val_df_loaded = val_table.get_dataframe()\n",
        "                test_df_loaded = test_table.get_dataframe()\n",
        "\n",
        "                # Update variables to use loaded splits\n",
        "                train_questions_loaded = train_df_loaded['question'].tolist()\n",
        "                train_answers_loaded = train_df_loaded['answer'].tolist()\n",
        "                val_questions_loaded = val_df_loaded['question'].tolist()\n",
        "                val_answers_loaded = val_df_loaded['answer'].tolist()\n",
        "                test_questions_loaded = test_df_loaded['question'].tolist()\n",
        "                test_answers_loaded = test_df_loaded['answer'].tolist()\n",
        "\n",
        "                # Use loaded splits for consistency\n",
        "                train_questions = train_questions_loaded\n",
        "                train_answers = train_answers_loaded\n",
        "                val_questions = val_questions_loaded\n",
        "                val_answers = val_answers_loaded\n",
        "                test_questions = test_questions_loaded\n",
        "                test_answers = test_answers_loaded\n",
        "\n",
        "                # Update training data and corpus\n",
        "                train_subset_questions = train_questions[:train_subset_size]\n",
        "                train_subset_answers = train_answers[:train_subset_size]\n",
        "                train_data = [(q, a) for q, a in zip(train_subset_questions, train_subset_answers)]\n",
        "                corpus_for_negatives = train_answers.copy()\n",
        "\n",
        "                dataset_loaded_from_wandb = True\n",
        "                print(f\"   ‚Ä¢ Training set: {len(train_questions):,} QA pairs\")\n",
        "                print(f\"   ‚Ä¢ Validation set: {len(val_questions):,} QA pairs\")\n",
        "                print(f\"   ‚Ä¢ Test set: {len(test_questions):,} QA pairs\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ÑπÔ∏è No existing dataset splits found: {e}\")\n",
        "                print(f\"üìä Creating new dataset splits artifact...\")\n",
        "\n",
        "                # Create and log dataset split artifacts\n",
        "                split_artifact = wandb.Artifact(dataset_artifact_name, type=\"dataset_split\")\n",
        "\n",
        "                # Convert to dataframes and add to artifact\n",
        "                train_split_df = pd.DataFrame({\n",
        "                    'question': train_questions,\n",
        "                    'answer': train_answers,\n",
        "                    'dataset_source': ['mixed'] * len(train_questions)  # Add source info\n",
        "                })\n",
        "                val_split_df = pd.DataFrame({\n",
        "                    'question': val_questions,\n",
        "                    'answer': val_answers,\n",
        "                    'dataset_source': ['mixed'] * len(val_questions)\n",
        "                })\n",
        "                test_split_df = pd.DataFrame({\n",
        "                    'question': test_questions,\n",
        "                    'answer': test_answers,\n",
        "                    'dataset_source': ['mixed'] * len(test_questions)\n",
        "                })\n",
        "\n",
        "                # Log as wandb Tables\n",
        "                split_artifact.add(wandb.Table(dataframe=train_split_df), 'train_data_frame')\n",
        "                split_artifact.add(wandb.Table(dataframe=val_split_df), 'val_data_frame')\n",
        "                split_artifact.add(wandb.Table(dataframe=test_split_df), 'test_data_frame')\n",
        "\n",
        "                run.log_artifact(split_artifact)\n",
        "                print(f\"‚úÖ Dataset splits saved as wandb artifact: {split_artifact.name}\")\n",
        "                dataset_loaded_from_wandb = False\n",
        "\n",
        "            # Log dataset info\n",
        "            wandb.log({\n",
        "                \"dataset/train_size\": len(train_questions),\n",
        "                \"dataset/val_size\": len(val_questions),\n",
        "                \"dataset/test_size\": len(test_questions),\n",
        "                \"dataset/total_size\": len(train_questions) + len(val_questions) + len(test_questions),\n",
        "                \"dataset/loaded_from_wandb\": dataset_loaded_from_wandb\n",
        "            })\n",
        "\n",
        "            # Log initial dataset and hyperparameters\n",
        "            if wandb.run:\n",
        "                 wandb.config.update({\n",
        "                    \"dataset_train_size\": len(train_data),\n",
        "                    \"dataset_val_size\": len(val_questions),\n",
        "                    \"dataset_test_size\": len(test_questions),\n",
        "                    \"model_name\": 'bert-base-uncased', # Assuming this is the model name\n",
        "                    \"projection_dim\": dpr_trainer.projection_dim,\n",
        "                    \"learning_rate\": dpr_trainer.optimizer.param_groups[0]['lr'], # Get current LR\n",
        "                    \"num_epochs\": num_epochs,\n",
        "                    \"batch_size\": batch_size,\n",
        "                    \"negative_sampling\": \"in-batch only\",\n",
        "                    \"dataset_loaded_from_wandb\": dataset_loaded_from_wandb\n",
        "                })\n",
        "                 print(\"Logged dataset size and hyperparameters to wandb.\")\n",
        "\n",
        "            for epoch in range(start_epoch, start_epoch + num_epochs): # Adjust loop to start from loaded epoch\n",
        "                print(f\"\\nüìÖ Epoch {epoch + 1}/{start_epoch + num_epochs}\")\n",
        "\n",
        "                # Train one epoch and get comprehensive validation metrics\n",
        "                avg_loss, epoch_metrics = dpr_trainer.train_epoch(train_data, batch_size=batch_size, epoch=epoch, val_questions=val_questions, val_answers=val_answers)\n",
        "\n",
        "                # Store metrics\n",
        "                training_losses.append(avg_loss)\n",
        "                epoch_metrics_history.append(epoch_metrics)\n",
        "\n",
        "                print(f\"   ‚Ä¢ Training loss: {avg_loss:.4f}\")\n",
        "                print(f\"   ‚Ä¢ Validation Results:\")\n",
        "                print(f\"     - Top-1 accuracy: {epoch_metrics['top_1_accuracy']:.3f}\")\n",
        "                print(f\"     - Top-5 accuracy: {epoch_metrics['top_5_accuracy']:.3f}\")\n",
        "                print(f\"     - Top-10 accuracy: {epoch_metrics['top_10_accuracy']:.3f}\")\n",
        "                print(f\"     - Top-20 accuracy: {epoch_metrics['top_20_accuracy']:.3f}\")\n",
        "                print(f\"     - Exact Match: {epoch_metrics['exact_match']:.3f}\")\n",
        "                print(f\"     - F1 Score: {epoch_metrics['f1']:.3f}\")\n",
        "\n",
        "                # Add memory monitoring (example for CPU, adjust for GPU if needed)\n",
        "                import psutil\n",
        "                process = psutil.Process(os.getpid())\n",
        "                mem_info = process.memory_info()\n",
        "                print(f\"   ‚Ä¢ Memory usage after epoch {epoch+1}: {mem_info.rss / (1024 * 1024):.2f} MB\")\n",
        "\n",
        "        print(f\"‚úÖ DPR training completed!\")\n",
        "\n",
        "        # ===== DPR EVALUATION ON TEST SET =====\n",
        "        print(f\"\\nüîç Evaluating DPR on test set...\")\n",
        "\n",
        "        # Use full test set for evaluation\n",
        "        test_size = len(test_questions)\n",
        "        print(f\"   ‚Ä¢ Test set size: {test_size:,} QA pairs\")\n",
        "\n",
        "        # Encode test passages\n",
        "        test_passage_embeddings = dpr_trainer.encode_for_retrieval(test_answers, 'passage')\n",
        "\n",
        "        # Evaluate on test set\n",
        "        dpr_predictions = []\n",
        "        top_k_accuracies = {1: 0, 5: 0, 10: 0, 20: 0} # Added top 20\n",
        "\n",
        "        for i, question in enumerate(test_questions):\n",
        "            results_list = dpr_trainer.retrieve(question, test_passage_embeddings, test_answers, top_k=20) # Retrieve top 20\n",
        "\n",
        "            if results_list:\n",
        "                # Get top-1 prediction\n",
        "                best_answer = results_list[0][2]\n",
        "                dpr_predictions.append(best_answer)\n",
        "\n",
        "                # Calculate top-k accuracies\n",
        "                correct_answer = test_answers[i]\n",
        "                retrieved_answers = [r[2] for r in results_list]\n",
        "\n",
        "                for k in [1, 5, 10, 20]: # Added top 20\n",
        "                    if correct_answer in retrieved_answers[:k]:\n",
        "                        top_k_accuracies[k] += 1\n",
        "            else:\n",
        "                dpr_predictions.append(\"\")\n",
        "\n",
        "        # Calculate final metrics\n",
        "        for k in top_k_accuracies:\n",
        "            top_k_accuracies[k] = top_k_accuracies[k] / test_size if test_size > 0 else 0.0\n",
        "\n",
        "        # QA performance metrics\n",
        "        dpr_qa_results = evaluator.evaluate_qa_performance(dpr_predictions, test_answers)\n",
        "\n",
        "        # Store results with epoch-by-epoch metrics\n",
        "        results['DPR_Trained'] = {\n",
        "            **dpr_qa_results,\n",
        "            'top_1_accuracy': top_k_accuracies[1],\n",
        "            'top_5_accuracy': top_k_accuracies[5],\n",
        "            'top_10_accuracy': top_k_accuracies[10],\n",
        "            'top_20_accuracy': top_k_accuracies[20], # Added top 20\n",
        "            'training_losses': training_losses,\n",
        "            'epoch_metrics_history': epoch_metrics_history,  # Store comprehensive epoch history\n",
        "            'test_size': test_size,\n",
        "            'dataset_loaded_from_wandb': dataset_loaded_from_wandb\n",
        "        }\n",
        "\n",
        "        print(f\"‚úÖ DPR Test Results:\")\n",
        "        print(f\"   ‚Ä¢ Test set size: {test_size:,}\")\n",
        "        print(f\"   ‚Ä¢ Top-1 accuracy: {top_k_accuracies[1]:.3f}\")\n",
        "        print(f\"   ‚Ä¢ Top-5 accuracy: {top_k_accuracies[5]:.3f}\")\n",
        "        print(f\"   ‚Ä¢ Top-10 accuracy: {top_k_accuracies[10]:.3f}\")\n",
        "        print(f\"   ‚Ä¢ Top-20 accuracy: {top_k_accuracies[20]:.3f}\") # Added top 20\n",
        "        print(f\"   ‚Ä¢ QA Exact Match: {dpr_qa_results['exact_match']:.3f}\")\n",
        "        print(f\"   ‚Ä¢ QA F1 Score: {dpr_qa_results['f1']:.3f}\")\n",
        "\n",
        "        # Log test results to wandb\n",
        "        with wandb.init(project=\"Domain QA\", name=\"DPR Training\", resume=True) as run:\n",
        "            wandb.log({\n",
        "                \"dpr/test_top_1_accuracy\": top_k_accuracies[1],\n",
        "                \"dpr/test_top_5_accuracy\": top_k_accuracies[5],\n",
        "                \"dpr/test_top_10_accuracy\": top_k_accuracies[10],\n",
        "                \"dpr/test_top_20_accuracy\": top_k_accuracies[20],\n",
        "                \"dpr/test_exact_match\": dpr_qa_results['exact_match'],\n",
        "                \"dpr/test_f1\": dpr_qa_results['f1']\n",
        "            })\n",
        "\n",
        "        # Print epoch-by-epoch summary\n",
        "        print(f\"\\nüìä DPR Epoch-by-Epoch Summary:\")\n",
        "        print(f\"{'Epoch':<6} {'Loss':<8} {'Top-1':<8} {'Top-5':<8} {'Top-10':<8} {'Top-20':<8} {'EM':<8} {'F1':<8}\")\n",
        "        print(\"-\" * 65)\n",
        "        for i, (loss, metrics) in enumerate(zip(training_losses, epoch_metrics_history)):\n",
        "            epoch_num = start_epoch + i + 1\n",
        "            print(f\"{epoch_num:<6} {loss:<8.4f} {metrics['top_1_accuracy']:<8.3f} {metrics['top_5_accuracy']:<8.3f} {metrics['top_10_accuracy']:<8.3f} {metrics['top_20_accuracy']:<8.3f} {metrics['exact_match']:<8.3f} {metrics['f1']:<8.3f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå DPR training/evaluation failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        results['DPR_Trained'] = {'exact_match': 0.0, 'f1': 0.0, 'count': 0, 'test_size': 0, 'top_1_accuracy': 0.0, 'top_5_accuracy': 0.0, 'top_10_accuracy': 0.0, 'top_20_accuracy': 0.0, 'training_losses': [], 'epoch_metrics_history': []} # Added epoch_metrics_history\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è DPR trainer not available - using placeholder results\")\n",
        "    results['DPR_Trained'] = {'exact_match': 0.0, 'f1': 0.0, 'count': 0, 'test_size': 0, 'top_1_accuracy': 0.0, 'top_5_accuracy': 0.0, 'top_10_accuracy': 0.0, 'top_20_accuracy': 0.0, 'training_losses': [], 'epoch_metrics_history': []} # Added epoch_metrics_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHWj7SbJqoMP"
      },
      "outputs": [],
      "source": [
        "# ===== SPLADE TRAINING AND EVALUATION =====\n",
        "print(f\"\\nüîç SPLADE NEURAL SPARSE RETRIEVAL TRAINING & EVALUATION\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "if DL_LIBRARIES_AVAILABLE and splade_trainer is not None:\n",
        "    try:\n",
        "        # Training parameters\n",
        "        num_epochs = 7 # Reduced for resource efficiency\n",
        "        batch_size = 4 # Reduced for resource efficiency\n",
        "\n",
        "        print(f\"üéØ SPLADE Training configuration:\")\n",
        "        print(f\"   ‚Ä¢ Epochs: {num_epochs}\")\n",
        "        print(f\"   ‚Ä¢ Batch size: {batch_size}\")\n",
        "        print(f\"   ‚Ä¢ Regularization: FLOPS (Œª_q={splade_trainer.lambda_q}, Œª_d={splade_trainer.lambda_d})\")\n",
        "\n",
        "        # Training loop with comprehensive epoch-by-epoch metrics tracking\n",
        "        print(f\"\\nüèÉ Training SPLADE...\")\n",
        "        training_losses = []\n",
        "        epoch_metrics_history = []  # Store all epoch metrics\n",
        "\n",
        "        # Use wandb.init() as a context manager for training\n",
        "        with wandb.init(project=\"Domain QA\", name=\"SPLADE Training\", config={\n",
        "            \"model_name\": 'bert-base-uncased', # Assuming this is the model name\n",
        "            \"learning_rate\": splade_trainer.optimizer.param_groups[0]['lr'], # Get current LR\n",
        "            \"num_epochs\": num_epochs,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"lambda_q\": splade_trainer.lambda_q,\n",
        "            \"lambda_d\": splade_trainer.lambda_d,\n",
        "            \"negative_sampling_strategy\": \"random_from_corpus\"\n",
        "        }) as run:\n",
        "            # ===== DATASET SPLIT HANDLING WITHIN TRAINING RUN =====\n",
        "            print(\"üìä Checking for existing dataset splits in wandb...\")\n",
        "            dataset_loaded_from_wandb = False\n",
        "            dataset_artifact_name = \"covid-qa-splits\"  # Same artifact name as DPR for consistency\n",
        "\n",
        "            # Check if artifact already exists and load or create\n",
        "            try:\n",
        "                existing_artifact = run.use_artifact(f\"{dataset_artifact_name}:latest\", type=\"dataset_split\")\n",
        "                print(f\"‚úÖ Found existing dataset splits, loading from wandb (same as DPR):\")\n",
        "                print(f\"   ‚Ä¢ Using artifact: {existing_artifact.name}\")\n",
        "\n",
        "                # Load the dataset splits from wandb tables\n",
        "                train_table = existing_artifact.get(\"train_data_frame\")\n",
        "                val_table = existing_artifact.get(\"val_data_frame\")\n",
        "                test_table = existing_artifact.get(\"test_data_frame\")\n",
        "\n",
        "                # Convert back to lists\n",
        "                train_df_loaded = train_table.get_dataframe()\n",
        "                val_df_loaded = val_table.get_dataframe()\n",
        "                test_df_loaded = test_table.get_dataframe()\n",
        "\n",
        "                # Update variables to use loaded splits (same as DPR)\n",
        "                train_questions_loaded = train_df_loaded['question'].tolist()\n",
        "                train_answers_loaded = train_df_loaded['answer'].tolist()\n",
        "                val_questions_loaded = val_df_loaded['question'].tolist()\n",
        "                val_answers_loaded = val_df_loaded['answer'].tolist()\n",
        "                test_questions_loaded = test_df_loaded['question'].tolist()\n",
        "                test_answers_loaded = test_df_loaded['answer'].tolist()\n",
        "\n",
        "                # Use loaded splits for consistency with DPR\n",
        "                train_questions = train_questions_loaded\n",
        "                train_answers = train_answers_loaded\n",
        "                val_questions = val_questions_loaded\n",
        "                val_answers = val_answers_loaded\n",
        "                test_questions = test_questions_loaded\n",
        "                test_answers = test_answers_loaded\n",
        "\n",
        "                # Update training data and corpus\n",
        "                train_subset_questions = train_questions[:len(train_questions)]  # Use full training set\n",
        "                train_subset_answers = train_answers[:len(train_answers)]\n",
        "                corpus_for_negatives = train_answers.copy()\n",
        "\n",
        "                dataset_loaded_from_wandb = True\n",
        "                print(f\"   ‚Ä¢ Training set: {len(train_questions):,} QA pairs\")\n",
        "                print(f\"   ‚Ä¢ Validation set: {len(val_questions):,} QA pairs\")\n",
        "                print(f\"   ‚Ä¢ Test set: {len(test_questions):,} QA pairs\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ÑπÔ∏è No existing dataset splits found: {e}\")\n",
        "                print(f\"üìä SPLADE will use current dataset splits (not creating new artifact)\")\n",
        "                dataset_loaded_from_wandb = False\n",
        "                # Note: Don't create new artifact here since DPR should have created it\n",
        "\n",
        "            # Prepare training data with negatives using the correct dataset\n",
        "            print(\"üîß Preparing SPLADE training data with negative sampling...\")\n",
        "\n",
        "            # Create negative samples for training\n",
        "            splade_train_data = []\n",
        "            possible_negatives_corpus = [a for a in corpus_for_negatives if a not in train_subset_answers] # Use answers not in the training subset as potential negatives\n",
        "            if not possible_negatives_corpus:\n",
        "                 possible_negatives_corpus = corpus_for_negatives # Fallback to full corpus if no non-training answers available\n",
        "\n",
        "            for i, (question, pos_answer) in enumerate(zip(train_subset_questions, train_subset_answers)):\n",
        "                # Random negative from corpus\n",
        "                # Ensure the negative sample is different from the positive sample\n",
        "                possible_negatives = [a for a in possible_negatives_corpus if a != pos_answer]\n",
        "                if possible_negatives: # Only add if a negative sample can be found\n",
        "                    neg_answer = np.random.choice(possible_negatives)\n",
        "                    splade_train_data.append((question, pos_answer, neg_answer))\n",
        "                else:\n",
        "                     print(f\"Skipping training example {i} due to lack of suitable negative sample.\")\n",
        "\n",
        "            if not splade_train_data:\n",
        "                print(\"‚ö†Ô∏è No valid SPLADE training data triplets could be generated. Skipping SPLADE training.\")\n",
        "                results['SPLADE_Trained'] = {'exact_match': 0.0, 'f1': 0.0, 'count': 0, 'test_size': 0, 'epoch_metrics_history': []}\n",
        "                return\n",
        "\n",
        "            print(f\"   ‚Ä¢ Training triplets: {len(splade_train_data):,}\")\n",
        "            print(f\"   ‚Ä¢ Corpus for negatives: {len(corpus_for_negatives):,} passages\")\n",
        "\n",
        "            # Log dataset info\n",
        "            wandb.log({\n",
        "                \"dataset/train_size\": len(train_questions),\n",
        "                \"dataset/val_size\": len(val_questions),\n",
        "                \"dataset/test_size\": len(test_questions),\n",
        "                \"dataset/total_size\": len(train_questions) + len(val_questions) + len(test_questions),\n",
        "                \"dataset/loaded_from_wandb\": dataset_loaded_from_wandb,\n",
        "                \"dataset/splade_triplets\": len(splade_train_data),\n",
        "                \"dataset/unified_with_dpr\": True\n",
        "            })\n",
        "\n",
        "            # Log initial dataset and hyperparameters\n",
        "            if wandb.run:\n",
        "                wandb.config.update({\n",
        "                    \"dataset_train_size\": len(splade_train_data),\n",
        "                    \"dataset_val_size\": len(val_questions),\n",
        "                    \"dataset_test_size\": len(test_questions),\n",
        "                    \"model_name\": 'bert-base-uncased', # Assuming this is the model name\n",
        "                    \"learning_rate\": splade_trainer.optimizer.param_groups[0]['lr'], # Get current LR\n",
        "                    \"num_epochs\": num_epochs,\n",
        "                    \"batch_size\": batch_size,\n",
        "                    \"lambda_q\": splade_trainer.lambda_q,\n",
        "                    \"lambda_d\": splade_trainer.lambda_d,\n",
        "                    \"unified_dataset\": True,  # Flag to indicate same dataset as DPR\n",
        "                    \"negative_sampling_strategy\": \"random_from_corpus\",\n",
        "                    \"dataset_loaded_from_wandb\": dataset_loaded_from_wandb\n",
        "                })\n",
        "                print(\"Logged dataset size and hyperparameters to wandb.\")\n",
        "\n",
        "            for epoch in range(num_epochs):\n",
        "                print(f\"\\nüìÖ Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "                # Train one epoch and get comprehensive validation metrics\n",
        "                epoch_metrics = splade_trainer.train_epoch(splade_train_data, batch_size=batch_size, epoch=epoch, val_questions=val_questions, val_answers=val_answers)\n",
        "\n",
        "                # Store metrics\n",
        "                training_losses.append(epoch_metrics['total_loss'])\n",
        "                epoch_metrics_history.append(epoch_metrics)\n",
        "\n",
        "                print(f\"   ‚Ä¢ Training Losses:\")\n",
        "                print(f\"     - Total loss: {epoch_metrics['total_loss']:.4f}\")\n",
        "                print(f\"     - Ranking loss: {epoch_metrics['ranking_loss']:.4f}\")\n",
        "                print(f\"     - Regularization loss: {epoch_metrics['reg_loss']:.4f}\")\n",
        "                print(f\"   ‚Ä¢ Validation Results:\")\n",
        "                print(f\"     - Top-1 accuracy: {epoch_metrics['top_1_accuracy']:.3f}\")\n",
        "                print(f\"     - Top-5 accuracy: {epoch_metrics['top_5_accuracy']:.3f}\")\n",
        "                print(f\"     - Top-10 accuracy: {epoch_metrics['top_10_accuracy']:.3f}\")\n",
        "                print(f\"     - Top-20 accuracy: {epoch_metrics['top_20_accuracy']:.3f}\")\n",
        "                print(f\"     - Exact Match: {epoch_metrics['exact_match']:.3f}\")\n",
        "                print(f\"     - F1 Score: {epoch_metrics['f1']:.3f}\")\n",
        "\n",
        "        print(f\"‚úÖ SPLADE training completed!\")\n",
        "\n",
        "        # ===== SPLADE EVALUATION ON TEST SET =====\n",
        "        print(f\"\\nüîç Evaluating SPLADE on test set...\")\n",
        "        print(f\"   ‚Ä¢ Using same test set as DPR for fair comparison\")\n",
        "\n",
        "        # Use full test set for evaluation (same as DPR)\n",
        "        test_size = len(test_questions)\n",
        "        print(f\"   ‚Ä¢ Test set size: {test_size:,} QA pairs\")\n",
        "\n",
        "        # Encode test documents\n",
        "        test_doc_representations = splade_trainer.encode_for_retrieval(test_answers)\n",
        "\n",
        "        # Get sparsity statistics\n",
        "        sparsity_stats = splade_trainer.get_sparse_statistics(test_doc_representations)\n",
        "        print(f\"   ‚Ä¢ Sparsity statistics:\")\n",
        "        print(f\"      - Avg non-zero terms: {sparsity_stats['avg_non_zero_terms']:.1f}\")\n",
        "        print(f\"      - Avg sparsity: {sparsity_stats['avg_sparsity']:.3f}\")\n",
        "\n",
        "        # Evaluate on test set\n",
        "        splade_predictions = []\n",
        "        top_k_accuracies = {1: 0, 5: 0, 10: 0, 20: 0}  # Added top-20\n",
        "\n",
        "        for i, question in enumerate(test_questions):\n",
        "            results_list = splade_trainer.retrieve(question, test_doc_representations, test_answers, top_k=20)  # Changed to top-20\n",
        "\n",
        "            if results_list:\n",
        "                # Get top-1 prediction\n",
        "                best_answer = results_list[0][2]\n",
        "                splade_predictions.append(best_answer)\n",
        "\n",
        "                # Calculate top-k accuracies\n",
        "                correct_answer = test_answers[i]\n",
        "                retrieved_answers = [r[2] for r in results_list]\n",
        "\n",
        "                for k in [1, 5, 10, 20]:  # Added top-20\n",
        "                    if correct_answer in retrieved_answers[:k]:\n",
        "                        top_k_accuracies[k] += 1\n",
        "            else:\n",
        "                splade_predictions.append(\"\")\n",
        "\n",
        "        # Calculate final metrics\n",
        "        for k in top_k_accuracies:\n",
        "            top_k_accuracies[k] = top_k_accuracies[k] / test_size if test_size > 0 else 0.0\n",
        "\n",
        "        # QA performance metrics\n",
        "        splade_qa_results = evaluator.evaluate_qa_performance(splade_predictions, test_answers)\n",
        "\n",
        "        # Store results with epoch-by-epoch metrics\n",
        "        results['SPLADE_Trained'] = {\n",
        "            **splade_qa_results,\n",
        "            'top_1_accuracy': top_k_accuracies[1],\n",
        "            'top_5_accuracy': top_k_accuracies[5],\n",
        "            'top_10_accuracy': top_k_accuracies[10],\n",
        "            'top_20_accuracy': top_k_accuracies[20],  # Added top-20\n",
        "            'training_losses': training_losses,\n",
        "            'epoch_metrics_history': epoch_metrics_history,  # Store comprehensive epoch history\n",
        "            'sparsity_stats': sparsity_stats,\n",
        "            'test_size': test_size,\n",
        "            'unified_dataset': True,  # Flag to indicate same dataset as DPR\n",
        "            'dataset_loaded_from_wandb': dataset_loaded_from_wandb\n",
        "        }\n",
        "\n",
        "        print(f\"‚úÖ SPLADE Test Results:\")\n",
        "        print(f\"   ‚Ä¢ Test set size: {test_size:,}\")\n",
        "        print(f\"   ‚Ä¢ Top-1 accuracy: {top_k_accuracies[1]:.3f}\")\n",
        "        print(f\"   ‚Ä¢ Top-5 accuracy: {top_k_accuracies[5]:.3f}\")\n",
        "        print(f\"   ‚Ä¢ Top-10 accuracy: {top_k_accuracies[10]:.3f}\")\n",
        "        print(f\"   ‚Ä¢ Top-20 accuracy: {top_k_accuracies[20]:.3f}\")  # Added top-20\n",
        "        print(f\"   ‚Ä¢ QA Exact Match: {splade_qa_results['exact_match']:.3f}\")\n",
        "        print(f\"   ‚Ä¢ QA F1 Score: {splade_qa_results['f1']:.3f}\")\n",
        "\n",
        "        # Log test results to wandb\n",
        "        with wandb.init(project=\"Domain QA\", name=\"SPLADE Training\", resume=True) as run:\n",
        "            wandb.log({\n",
        "                \"splade/test_top_1_accuracy\": top_k_accuracies[1],\n",
        "                \"splade/test_top_5_accuracy\": top_k_accuracies[5],\n",
        "                \"splade/test_top_10_accuracy\": top_k_accuracies[10],\n",
        "                \"splade/test_top_20_accuracy\": top_k_accuracies[20],\n",
        "                \"splade/test_exact_match\": splade_qa_results['exact_match'],\n",
        "                \"splade/test_f1\": splade_qa_results['f1'],\n",
        "                \"splade/avg_non_zero_terms\": sparsity_stats['avg_non_zero_terms'],\n",
        "                \"splade/avg_sparsity\": sparsity_stats['avg_sparsity']\n",
        "            })\n",
        "\n",
        "        # Print epoch-by-epoch summary\n",
        "        print(f\"\\nüìä SPLADE Epoch-by-Epoch Summary:\")\n",
        "        print(f\"{'Epoch':<6} {'Total Loss':<12} {'Ranking Loss':<14} {'Reg Loss':<10} {'Top-1':<8} {'Top-5':<8} {'Top-10':<8} {'Top-20':<8} {'EM':<8} {'F1':<8}\")\n",
        "        print(\"-\" * 95)\n",
        "        for i, metrics in enumerate(epoch_metrics_history):\n",
        "            epoch_num = i + 1\n",
        "            print(f\"{epoch_num:<6} {metrics['total_loss']:<12.4f} {metrics['ranking_loss']:<14.4f} {metrics['reg_loss']:<10.4f} {metrics['top_1_accuracy']:<8.3f} {metrics['top_5_accuracy']:<8.3f} {metrics['top_10_accuracy']:<8.3f} {metrics['top_20_accuracy']:<8.3f} {metrics['exact_match']:<8.3f} {metrics['f1']:<8.3f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå SPLADE training/evaluation failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        results['SPLADE_Trained'] = {'exact_match': 0.0, 'f1': 0.0, 'count': 0, 'test_size': 0, 'epoch_metrics_history': []}\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è SPLADE trainer not available - using placeholder results\")\n",
        "    results['SPLADE_Trained'] = {'exact_match': 0.0, 'f1': 0.0, 'count': 0, 'test_size': 0, 'epoch_metrics_history': []}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYQsQrf2sNhq"
      },
      "outputs": [],
      "source": [
        "# Step 6: Analysis and Comparison with Traditional Methods\n",
        "\n",
        "print(\"üî¨ COMPREHENSIVE ANALYSIS: DEEP LEARNING vs TRADITIONAL METHODS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Load traditional methods results (from Chapter 4)\n",
        "traditional_results = {\n",
        "    'TF-IDF': {'exact_match': 0.275, 'f1': 0.403, 'count': 200},\n",
        "    'BM25': {'exact_match': 0.385, 'f1': 0.505, 'count': 200}\n",
        "}\n",
        "\n",
        "# Combine all results (handle case where results might be empty)\n",
        "if results:\n",
        "    all_results = {**traditional_results, **results}\n",
        "else:\n",
        "    all_results = traditional_results\n",
        "\n",
        "print(\"üìä COMPLETE PERFORMANCE COMPARISON:\")\n",
        "print(f\"{'Method':<15} {'Type':<12} {'Exact Match':<12} {'F1 Score':<10} {'Evaluated':<10}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Traditional methods\n",
        "print(f\"{'TF-IDF':<15} {'Traditional':<12} {traditional_results['TF-IDF']['exact_match']:<12.3f} {traditional_results['TF-IDF']['f1']:<10.3f} {traditional_results['TF-IDF']['count']:<10}\")\n",
        "print(f\"{'BM25':<15} {'Traditional':<12} {traditional_results['BM25']['exact_match']:<12.3f} {traditional_results['BM25']['f1']:<10.3f} {traditional_results['BM25']['count']:<10}\")\n",
        "\n",
        "# Deep learning methods\n",
        "for method, result in results.items():\n",
        "    method_type = 'Dense' if method == 'DPR' else 'Neural Sparse'\n",
        "    print(f\"{method:<15} {method_type:<12} {result['exact_match']:<12.3f} {result['f1']:<10.3f} {result['count']:<10}\")\n",
        "\n",
        "# Find best overall method\n",
        "best_method = max(all_results.keys(), key=lambda x: all_results[x]['f1'])\n",
        "print(f\"\\nüèÜ BEST OVERALL METHOD: {best_method}\")\n",
        "print(f\"   ‚Ä¢ F1 Score: {all_results[best_method]['f1']:.3f}\")\n",
        "print(f\"   ‚Ä¢ Exact Match: {all_results[best_method]['exact_match']:.3f}\")\n",
        "\n",
        "# Method comparison analysis\n",
        "print(f\"\\nüí° DETAILED ANALYSIS:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"1. TRADITIONAL METHODS PERFORMANCE:\")\n",
        "avg_traditional_f1 = np.mean([traditional_results[m]['f1'] for m in traditional_results])\n",
        "print(f\"   ‚Ä¢ Average F1: {avg_traditional_f1:.3f}\")\n",
        "print(f\"   ‚Ä¢ BM25 outperforms TF-IDF by {traditional_results['BM25']['f1'] - traditional_results['TF-IDF']['f1']:.3f} F1 points\")\n",
        "print(f\"   ‚Ä¢ Strong baseline for medical domain terminology\")\n",
        "\n",
        "if results:\n",
        "    print(f\"\\n2. DEEP LEARNING METHODS PERFORMANCE:\")\n",
        "    avg_dl_f1 = np.mean([results[m]['f1'] for m in results])\n",
        "    print(f\"   ‚Ä¢ Average F1: {avg_dl_f1:.3f}\")\n",
        "\n",
        "    if 'DPR' in results and 'SPLADE' in results:\n",
        "        dpr_vs_splade = results['DPR']['f1'] - results['SPLADE']['f1']\n",
        "        better_dl = 'DPR' if dpr_vs_splade > 0 else 'SPLADE'\n",
        "        print(f\"   ‚Ä¢ {better_dl} outperforms by {abs(dpr_vs_splade):.3f} F1 points\")\n",
        "\n",
        "    print(f\"   ‚Ä¢ Semantic understanding vs interpretability trade-off\")\n",
        "\n",
        "    print(f\"\\n3. TRADITIONAL vs DEEP LEARNING:\")\n",
        "    best_traditional = max(traditional_results.keys(), key=lambda x: traditional_results[x]['f1'])\n",
        "    best_dl = max(results.keys(), key=lambda x: results[x]['f1'])\n",
        "\n",
        "    improvement = results[best_dl]['f1'] - traditional_results[best_traditional]['f1']\n",
        "    if improvement > 0:\n",
        "        print(f\"   ‚Ä¢ Deep learning improves by {improvement:.3f} F1 points\")\n",
        "        print(f\"   ‚Ä¢ {best_dl} beats {best_traditional} by {improvement:.3f}\")\n",
        "    else:\n",
        "        print(f\"   ‚Ä¢ Traditional methods competitive: {abs(improvement):.3f} gap\")\n",
        "        print(f\"   ‚Ä¢ {best_traditional} beats {best_dl} by {abs(improvement):.3f}\")\n",
        "\n",
        "print(f\"\\n4. MEDICAL DOMAIN INSIGHTS:\")\n",
        "print(f\"   ‚Ä¢ COVID-19 terminology challenges all methods\")\n",
        "print(f\"   ‚Ä¢ Semantic methods help with medical synonyms\")\n",
        "print(f\"   ‚Ä¢ Sparse methods maintain interpretability\")\n",
        "print(f\"   ‚Ä¢ Long medical answers reduce exact match scores\")\n",
        "\n",
        "print(f\"\\n5. METHOD CHARACTERISTICS:\")\n",
        "print(f\"   ‚Ä¢ TF-IDF: Fast, interpretable, keyword-based\")\n",
        "print(f\"   ‚Ä¢ BM25: Probabilistic ranking, length normalization\")\n",
        "print(f\"   ‚Ä¢ DPR: Dense semantic similarity, handles synonyms\")\n",
        "print(f\"   ‚Ä¢ SPLADE: Sparse neural expansion, interpretable\")\n",
        "\n",
        "print(f\"\\nüéØ RECOMMENDATIONS:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"‚Ä¢ For PRODUCTION: BM25 (reliable, fast, interpretable)\")\n",
        "print(f\"‚Ä¢ For RESEARCH: DPR/SPLADE (semantic understanding)\")\n",
        "print(f\"‚Ä¢ For MEDICAL DOMAIN: Hybrid approach combining methods\")\n",
        "print(f\"‚Ä¢ For INTERPRETABILITY: SPLADE (sparse + neural)\")\n",
        "\n",
        "print(f\"\\n‚úÖ COMPREHENSIVE ANALYSIS COMPLETE!\")\n",
        "print(f\"üìä All methods evaluated on COVID-QA medical domain dataset\")\n",
        "print(f\"üî¨ Results demonstrate trade-offs between speed, accuracy, and interpretability\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "scientificProject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "61eecc772a5b45d6a539c748fbb4e1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9e0ad48f29b4ac08eaf0f516cbc971c",
              "IPY_MODEL_9eaeaad999704d23b97ccac35f589504",
              "IPY_MODEL_11f31222b0bd469b86aa50bd53b9654c"
            ],
            "layout": "IPY_MODEL_2716ed75ea4e445cbbbb8a454a573547"
          }
        },
        "c9e0ad48f29b4ac08eaf0f516cbc971c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cf90e704a2b46c2a2d4f8a1ff5ef9c8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_34707047cf5f4b9ab5dcc854cfbc2422",
            "value": "config.json:‚Äá100%"
          }
        },
        "9eaeaad999704d23b97ccac35f589504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69997ad0a73b4ada8d285185f4257e27",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_600af2cd58f04576a7b37a5faf087fb3",
            "value": 570
          }
        },
        "11f31222b0bd469b86aa50bd53b9654c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8d4fcc392c7475d9985e1bfa3c5c403",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7a4c639eab6f48e9bf2149e8587a7cc6",
            "value": "‚Äá570/570‚Äá[00:00&lt;00:00,‚Äá55.8kB/s]"
          }
        },
        "2716ed75ea4e445cbbbb8a454a573547": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cf90e704a2b46c2a2d4f8a1ff5ef9c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34707047cf5f4b9ab5dcc854cfbc2422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69997ad0a73b4ada8d285185f4257e27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600af2cd58f04576a7b37a5faf087fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8d4fcc392c7475d9985e1bfa3c5c403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a4c639eab6f48e9bf2149e8587a7cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f813d72755940bb91a0a1bb3ef651a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa5e1d55e774413ca688f0a5e0d7c788",
              "IPY_MODEL_e43fdf6398da4bfdbb35a36b6ee559db",
              "IPY_MODEL_589b58c742dd4c13842480d313d09a3b"
            ],
            "layout": "IPY_MODEL_1ffeec198fce43efb4a8af6f66155a50"
          }
        },
        "aa5e1d55e774413ca688f0a5e0d7c788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e95fc1d10d1c45c8a841ed9203192a64",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5351742d64ae4235a607986c0bae2ea2",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "e43fdf6398da4bfdbb35a36b6ee559db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72ad0773b3054f54b229384f120f7d3a",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e959223194b942cc8af2c4a59fa818a9",
            "value": 440449768
          }
        },
        "589b58c742dd4c13842480d313d09a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830d236cee014cac906f2a951fb9255d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4de2b7454f76465cb62cc4e6561d0a4c",
            "value": "‚Äá440M/440M‚Äá[00:01&lt;00:00,‚Äá397MB/s]"
          }
        },
        "1ffeec198fce43efb4a8af6f66155a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e95fc1d10d1c45c8a841ed9203192a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5351742d64ae4235a607986c0bae2ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72ad0773b3054f54b229384f120f7d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e959223194b942cc8af2c4a59fa818a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "830d236cee014cac906f2a951fb9255d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4de2b7454f76465cb62cc4e6561d0a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb10244ca9124435a229068b16a4d4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a02f9a8e58949e3be976c2fc4b750ea",
              "IPY_MODEL_9e24c88ad5494b1a900fdd0bb4fd8565",
              "IPY_MODEL_56581235eecb45199ef20e47e7474465"
            ],
            "layout": "IPY_MODEL_8e55c059441446bfa99ed8b1b2acd58d"
          }
        },
        "2a02f9a8e58949e3be976c2fc4b750ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b936933003e94549b0bc212e6b92a87b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_37b8fdd7307843c0a39107b9690f9380",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "9e24c88ad5494b1a900fdd0bb4fd8565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19eac41c001649258981f2702123b5c9",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32608f26e2424ed29f26268f4e4dd90c",
            "value": 48
          }
        },
        "56581235eecb45199ef20e47e7474465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c5adb0412db4d2b85c607b7d93bcf04",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c22a908a6604479b8341ad0d095aae5d",
            "value": "‚Äá48.0/48.0‚Äá[00:00&lt;00:00,‚Äá5.59kB/s]"
          }
        },
        "8e55c059441446bfa99ed8b1b2acd58d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b936933003e94549b0bc212e6b92a87b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b8fdd7307843c0a39107b9690f9380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19eac41c001649258981f2702123b5c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32608f26e2424ed29f26268f4e4dd90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c5adb0412db4d2b85c607b7d93bcf04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c22a908a6604479b8341ad0d095aae5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "316ac419230240a686fc262be21ff5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef8d03837af3474aac6f86677de2982a",
              "IPY_MODEL_5906493105b4415c9917964354c5b74f",
              "IPY_MODEL_b39a3ce4080045f2ae5c290e76aba12d"
            ],
            "layout": "IPY_MODEL_cfecf6e6468f47bfbb732e975f9dbb6a"
          }
        },
        "ef8d03837af3474aac6f86677de2982a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7129af829b57492480901ab77bcb95be",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c165b859b0964bf19663076e92e1e6af",
            "value": "vocab.txt:‚Äá100%"
          }
        },
        "5906493105b4415c9917964354c5b74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf0b395bcf4341a6bcd2d1901d82f491",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c66e375115e46b1a755f1ea60800df3",
            "value": 231508
          }
        },
        "b39a3ce4080045f2ae5c290e76aba12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcef01737be94b9ab68be9898f1fd491",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e18cc7a784f64a0a91be42abaf6988ca",
            "value": "‚Äá232k/232k‚Äá[00:00&lt;00:00,‚Äá14.9MB/s]"
          }
        },
        "cfecf6e6468f47bfbb732e975f9dbb6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7129af829b57492480901ab77bcb95be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c165b859b0964bf19663076e92e1e6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf0b395bcf4341a6bcd2d1901d82f491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c66e375115e46b1a755f1ea60800df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcef01737be94b9ab68be9898f1fd491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e18cc7a784f64a0a91be42abaf6988ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10a092aec6994a9580dddc7eef53c418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19da33e3d83a4922bd894fdcb98c053b",
              "IPY_MODEL_a7927f3606a246278c9a52d916f3cdfa",
              "IPY_MODEL_529bf1d8e99046e9aa4adb9671802e81"
            ],
            "layout": "IPY_MODEL_f3ea517c03d546e0b5dfdaa64b8ece4b"
          }
        },
        "19da33e3d83a4922bd894fdcb98c053b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef4731826f844a5386962ec2f48e9436",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7f5f881fe4cb46c69c81f1fd00716be9",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "a7927f3606a246278c9a52d916f3cdfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f3a36b24ef0455eb9d920f70c7caf6d",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7254203a300f44a5949554414480414c",
            "value": 466062
          }
        },
        "529bf1d8e99046e9aa4adb9671802e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e577115d63f4a9a92dd69f9b6d3a555",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9d59233efb0f488d85bf2e986a569dea",
            "value": "‚Äá466k/466k‚Äá[00:00&lt;00:00,‚Äá36.0MB/s]"
          }
        },
        "f3ea517c03d546e0b5dfdaa64b8ece4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef4731826f844a5386962ec2f48e9436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5f881fe4cb46c69c81f1fd00716be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f3a36b24ef0455eb9d920f70c7caf6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7254203a300f44a5949554414480414c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e577115d63f4a9a92dd69f9b6d3a555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d59233efb0f488d85bf2e986a569dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}